{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-05T17:14:27.795052700Z",
     "start_time": "2024-03-05T17:14:27.682055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      eigencentrality     1                                 0         2  \\\n0            0.000000  62.0                          Dr. Hook  197908.0   \n1            0.000000   0.0  Johnny Rodriguez, Johnny Russell       7.0   \n2            0.002715  35.0                        Bill Smith     120.0   \n3            0.006510  20.0                       Cool Breeze    3321.0   \n4            0.000000  13.0                        The Clique     449.0   \n...               ...   ...                               ...       ...   \n6019         0.000000  10.0                        Navy Gravy     209.0   \n6020         0.000000  58.0                 Sweet Little Band   20088.0   \n6021         0.000000  38.0                     Chico DeBarge   60121.0   \n6022         0.002182   NaN                               NaN       NaN   \n6023         0.002182   NaN                               NaN       NaN   \n\n                                                      3  eccentricity  \\\n0     ['bubblegum pop', 'classic rock', 'classic uk ...           0.0   \n1                                                    []           0.0   \n2                                                    []           2.0   \n3                                                    []          12.0   \n4                                         ['freakbeat']           0.0   \n...                                                 ...           ...   \n6019                                                 []           0.0   \n6020                              ['musica para ninos']           0.0   \n6021  ['neo soul', 'new jack swing', 'r&b', 'urban c...           0.0   \n6022                                                NaN           1.0   \n6023                                                NaN           1.0   \n\n      betweenesscentrality  harmonicclosnesscentrality  \\\n0                      0.0                    0.000000   \n1                      0.0                    0.000000   \n2                      0.0                    0.833333   \n3                      0.0                    0.180073   \n4                      0.0                    0.000000   \n...                    ...                         ...   \n6019                   0.0                    0.000000   \n6020                   0.0                    0.000000   \n6021                   0.0                    0.000000   \n6022                   0.0                    1.000000   \n6023                   0.0                    1.000000   \n\n                  Spotify ID  degree  triangles  clustering  modularity_class  \\\n0     2Mhi3jfuRSdbVZPdjqsnnN       0          0         0.0                 0   \n1     4QFbv1d0BbQANO95hIQaZl       0          0         0.0                 1   \n2     4Omy5P9r7PiXYje9h4jMkz       2          1         1.0              3583   \n3     5vZr4eKCIxujg3mPZaHGcS       3          3         1.0              4549   \n4     1TYZpmNJCpmN38laFCVkCm       0          0         0.0                 2   \n...                      ...     ...        ...         ...               ...   \n6019  5QEZ8qPZSxIvzrkJCxlsn7       0          0         0.0              4748   \n6020  7HBA3bLuJTLRvjK8NX9ZSy       0          0         0.0              4749   \n6021  67ISVBZzcCTTKM17Ps00sx       0          0         0.0              4750   \n6022  10aVNpUB6sPjYjunSIIeq5       2          1         1.0              4751   \n6023  4LzaxCC42hkpnsbfMzk6RQ       2          1         1.0              4751   \n\n      closnesscentrality  weighted degree  \n0               0.000000              0.0  \n1               0.000000              0.0  \n2               0.750000              8.0  \n3               0.165762              6.0  \n4               0.000000              0.0  \n...                  ...              ...  \n6019            0.000000              0.0  \n6020            0.000000              0.0  \n6021            0.000000              0.0  \n6022            1.000000              4.0  \n6023            1.000000              4.0  \n\n[6024 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eigencentrality</th>\n      <th>1</th>\n      <th>0</th>\n      <th>2</th>\n      <th>3</th>\n      <th>eccentricity</th>\n      <th>betweenesscentrality</th>\n      <th>harmonicclosnesscentrality</th>\n      <th>Spotify ID</th>\n      <th>degree</th>\n      <th>triangles</th>\n      <th>clustering</th>\n      <th>modularity_class</th>\n      <th>closnesscentrality</th>\n      <th>weighted degree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>62.0</td>\n      <td>Dr. Hook</td>\n      <td>197908.0</td>\n      <td>['bubblegum pop', 'classic rock', 'classic uk ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2Mhi3jfuRSdbVZPdjqsnnN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>Johnny Rodriguez, Johnny Russell</td>\n      <td>7.0</td>\n      <td>[]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4QFbv1d0BbQANO95hIQaZl</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002715</td>\n      <td>35.0</td>\n      <td>Bill Smith</td>\n      <td>120.0</td>\n      <td>[]</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>4Omy5P9r7PiXYje9h4jMkz</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>3583</td>\n      <td>0.750000</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.006510</td>\n      <td>20.0</td>\n      <td>Cool Breeze</td>\n      <td>3321.0</td>\n      <td>[]</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>0.180073</td>\n      <td>5vZr4eKCIxujg3mPZaHGcS</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>4549</td>\n      <td>0.165762</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>13.0</td>\n      <td>The Clique</td>\n      <td>449.0</td>\n      <td>['freakbeat']</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1TYZpmNJCpmN38laFCVkCm</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6019</th>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>Navy Gravy</td>\n      <td>209.0</td>\n      <td>[]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5QEZ8qPZSxIvzrkJCxlsn7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4748</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6020</th>\n      <td>0.000000</td>\n      <td>58.0</td>\n      <td>Sweet Little Band</td>\n      <td>20088.0</td>\n      <td>['musica para ninos']</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>7HBA3bLuJTLRvjK8NX9ZSy</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4749</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6021</th>\n      <td>0.000000</td>\n      <td>38.0</td>\n      <td>Chico DeBarge</td>\n      <td>60121.0</td>\n      <td>['neo soul', 'new jack swing', 'r&amp;b', 'urban c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>67ISVBZzcCTTKM17Ps00sx</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4750</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6022</th>\n      <td>0.002182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>10aVNpUB6sPjYjunSIIeq5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4751</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>6023</th>\n      <td>0.002182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>4LzaxCC42hkpnsbfMzk6RQ</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4751</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6024 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_nodes = pd.read_csv(\"../Java/resources/nodes_real.csv\", sep=\"\\t\")\n",
    "df_nodes.drop(columns=[\"label\", \"Id\", \"timeset\"], inplace=True)\n",
    "df_nodes.rename(columns={\"id\" : \"Spotify ID\"}, inplace=True)\n",
    "df_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Define dictionaries for id and title attributes\n",
    "id_dict = {\n",
    "    \"0\": \"name\",\n",
    "    \"1\": \"popularity\",\n",
    "    \"2\": \"followers\",\n",
    "    \"3\": \"genres\"\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T17:14:27.798053100Z",
     "start_time": "2024-03-05T17:14:27.738054100Z"
    }
   },
   "id": "d695ec44565f40d4"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      eigencentrality  popularity                              name  \\\n0            0.000000        62.0                          Dr. Hook   \n1            0.000000         0.0  Johnny Rodriguez, Johnny Russell   \n2            0.002715        35.0                        Bill Smith   \n3            0.006510        20.0                       Cool Breeze   \n4            0.000000        13.0                        The Clique   \n...               ...         ...                               ...   \n6019         0.000000        10.0                        Navy Gravy   \n6020         0.000000        58.0                 Sweet Little Band   \n6021         0.000000        38.0                     Chico DeBarge   \n6022         0.002182         NaN                               NaN   \n6023         0.002182         NaN                               NaN   \n\n      followers                                             genres  \\\n0      197908.0  ['bubblegum pop', 'classic rock', 'classic uk ...   \n1           7.0                                                 []   \n2         120.0                                                 []   \n3        3321.0                                                 []   \n4         449.0                                      ['freakbeat']   \n...         ...                                                ...   \n6019      209.0                                                 []   \n6020    20088.0                              ['musica para ninos']   \n6021    60121.0  ['neo soul', 'new jack swing', 'r&b', 'urban c...   \n6022        NaN                                                NaN   \n6023        NaN                                                NaN   \n\n      eccentricity  betweenesscentrality  harmonicclosnesscentrality  \\\n0              0.0                   0.0                    0.000000   \n1              0.0                   0.0                    0.000000   \n2              2.0                   0.0                    0.833333   \n3             12.0                   0.0                    0.180073   \n4              0.0                   0.0                    0.000000   \n...            ...                   ...                         ...   \n6019           0.0                   0.0                    0.000000   \n6020           0.0                   0.0                    0.000000   \n6021           0.0                   0.0                    0.000000   \n6022           1.0                   0.0                    1.000000   \n6023           1.0                   0.0                    1.000000   \n\n                  Spotify ID  degree  triangles  clustering  modularity_class  \\\n0     2Mhi3jfuRSdbVZPdjqsnnN       0          0         0.0                 0   \n1     4QFbv1d0BbQANO95hIQaZl       0          0         0.0                 1   \n2     4Omy5P9r7PiXYje9h4jMkz       2          1         1.0              3583   \n3     5vZr4eKCIxujg3mPZaHGcS       3          3         1.0              4549   \n4     1TYZpmNJCpmN38laFCVkCm       0          0         0.0                 2   \n...                      ...     ...        ...         ...               ...   \n6019  5QEZ8qPZSxIvzrkJCxlsn7       0          0         0.0              4748   \n6020  7HBA3bLuJTLRvjK8NX9ZSy       0          0         0.0              4749   \n6021  67ISVBZzcCTTKM17Ps00sx       0          0         0.0              4750   \n6022  10aVNpUB6sPjYjunSIIeq5       2          1         1.0              4751   \n6023  4LzaxCC42hkpnsbfMzk6RQ       2          1         1.0              4751   \n\n      closnesscentrality  weighted degree  \n0               0.000000              0.0  \n1               0.000000              0.0  \n2               0.750000              8.0  \n3               0.165762              6.0  \n4               0.000000              0.0  \n...                  ...              ...  \n6019            0.000000              0.0  \n6020            0.000000              0.0  \n6021            0.000000              0.0  \n6022            1.000000              4.0  \n6023            1.000000              4.0  \n\n[6024 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>eigencentrality</th>\n      <th>popularity</th>\n      <th>name</th>\n      <th>followers</th>\n      <th>genres</th>\n      <th>eccentricity</th>\n      <th>betweenesscentrality</th>\n      <th>harmonicclosnesscentrality</th>\n      <th>Spotify ID</th>\n      <th>degree</th>\n      <th>triangles</th>\n      <th>clustering</th>\n      <th>modularity_class</th>\n      <th>closnesscentrality</th>\n      <th>weighted degree</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>62.0</td>\n      <td>Dr. Hook</td>\n      <td>197908.0</td>\n      <td>['bubblegum pop', 'classic rock', 'classic uk ...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>2Mhi3jfuRSdbVZPdjqsnnN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>Johnny Rodriguez, Johnny Russell</td>\n      <td>7.0</td>\n      <td>[]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>4QFbv1d0BbQANO95hIQaZl</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002715</td>\n      <td>35.0</td>\n      <td>Bill Smith</td>\n      <td>120.0</td>\n      <td>[]</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.833333</td>\n      <td>4Omy5P9r7PiXYje9h4jMkz</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>3583</td>\n      <td>0.750000</td>\n      <td>8.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.006510</td>\n      <td>20.0</td>\n      <td>Cool Breeze</td>\n      <td>3321.0</td>\n      <td>[]</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>0.180073</td>\n      <td>5vZr4eKCIxujg3mPZaHGcS</td>\n      <td>3</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>4549</td>\n      <td>0.165762</td>\n      <td>6.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>13.0</td>\n      <td>The Clique</td>\n      <td>449.0</td>\n      <td>['freakbeat']</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1TYZpmNJCpmN38laFCVkCm</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6019</th>\n      <td>0.000000</td>\n      <td>10.0</td>\n      <td>Navy Gravy</td>\n      <td>209.0</td>\n      <td>[]</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>5QEZ8qPZSxIvzrkJCxlsn7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4748</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6020</th>\n      <td>0.000000</td>\n      <td>58.0</td>\n      <td>Sweet Little Band</td>\n      <td>20088.0</td>\n      <td>['musica para ninos']</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>7HBA3bLuJTLRvjK8NX9ZSy</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4749</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6021</th>\n      <td>0.000000</td>\n      <td>38.0</td>\n      <td>Chico DeBarge</td>\n      <td>60121.0</td>\n      <td>['neo soul', 'new jack swing', 'r&amp;b', 'urban c...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>67ISVBZzcCTTKM17Ps00sx</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>4750</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6022</th>\n      <td>0.002182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>10aVNpUB6sPjYjunSIIeq5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4751</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>6023</th>\n      <td>0.002182</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>4LzaxCC42hkpnsbfMzk6RQ</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>4751</td>\n      <td>1.000000</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6024 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nodes.rename(columns=id_dict, inplace=True)\n",
    "#df_nodes.sort_values(by=\"Spotify ID\", inplace=True)\n",
    "df_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T17:14:27.799053600Z",
     "start_time": "2024-03-05T17:14:27.750053500Z"
    }
   },
   "id": "ae780198c89dce6d"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2Mhi3jfuRSdbVZPdjqsnnN'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_4832\\3771512097.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[1;32m---> 12\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mMinMaxScaler\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;31m# Assuming df_nodes is your DataFrame\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;31m# Select only the columns to be normalized\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\utils\\_set_output.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[0;32m    155\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mwraps\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    156\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mwrapped\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 157\u001B[1;33m         \u001B[0mdata_to_wrap\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    158\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata_to_wrap\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtuple\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m             \u001B[1;31m# only wrap the first output for cross decomposition\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    160\u001B[0m             return_tuple = (\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[0;32m    912\u001B[0m         \u001B[1;31m# non-optimized default implementation; override when a better\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    913\u001B[0m         \u001B[1;31m# method is possible for a given clustering algorithm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0my\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    915\u001B[0m             \u001B[1;31m# fit method of arity 1 (unsupervised transformation)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 916\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    917\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    918\u001B[0m             \u001B[1;31m# fit method of arity 2 (supervised transformation)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    919\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    431\u001B[0m             \u001B[0mFitted\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    432\u001B[0m         \"\"\"\n\u001B[0;32m    433\u001B[0m         \u001B[1;31m# Reset internal state before fitting\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    434\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 435\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpartial_fit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1148\u001B[0m                 skip_parameter_validation=(\n\u001B[0;32m   1149\u001B[0m                     \u001B[0mprefer_skip_nested_validation\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mglobal_skip_validation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1150\u001B[0m                 )\n\u001B[0;32m   1151\u001B[0m             ):\n\u001B[1;32m-> 1152\u001B[1;33m                 \u001B[1;32mreturn\u001B[0m \u001B[0mfit_method\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    469\u001B[0m                 \u001B[1;34m\"Consider using MaxAbsScaler instead.\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    470\u001B[0m             )\n\u001B[0;32m    471\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    472\u001B[0m         \u001B[0mfirst_pass\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mhasattr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"n_samples_seen_\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 473\u001B[1;33m         X = self._validate_data(\n\u001B[0m\u001B[0;32m    474\u001B[0m             \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    475\u001B[0m             \u001B[0mreset\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mfirst_pass\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    476\u001B[0m             \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mFLOAT_DTYPES\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\base.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[0;32m    601\u001B[0m                 \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    602\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    603\u001B[0m                 \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    604\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 605\u001B[1;33m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"X\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    606\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[0mno_val_X\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mno_val_y\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    607\u001B[0m             \u001B[0mout\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_check_y\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    608\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    913\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m                 \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    915\u001B[0m                     \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_asarray_with_order\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mxp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mxp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    916\u001B[0m             \u001B[1;32mexcept\u001B[0m \u001B[0mComplexWarning\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mcomplex_warning\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 917\u001B[1;33m                 raise ValueError(\n\u001B[0m\u001B[0;32m    918\u001B[0m                     \u001B[1;34m\"Complex data not supported\\n{}\\n\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    919\u001B[0m                 ) from complex_warning\n\u001B[0;32m    920\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[1;31m# Use NumPy API to support order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    377\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcopy\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    378\u001B[0m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    379\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 380\u001B[1;33m             \u001B[0marray\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0morder\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    381\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    382\u001B[0m         \u001B[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    383\u001B[0m         \u001B[1;31m# container that is consistent with the input's namespace.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   1996\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__array__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mnpt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDTypeLike\u001B[0m \u001B[1;33m|\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mndarray\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1997\u001B[0m         \u001B[0mvalues\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1998\u001B[1;33m         \u001B[0marr\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1999\u001B[0m         if (\n\u001B[0;32m   2000\u001B[0m             \u001B[0mastype_is_view\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marr\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2001\u001B[0m             \u001B[1;32mand\u001B[0m \u001B[0musing_copy_on_write\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '2Mhi3jfuRSdbVZPdjqsnnN'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Assuming df_nodes is your DataFrame\n",
    "# Select only the columns to be normalized\n",
    "columns_to_normalize = df_nodes.columns[5:]  # Exclude the first and last columns\n",
    "data_to_normalize = df_nodes[columns_to_normalize]\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "normalized_data = scaler.fit_transform(data_to_normalize)\n",
    "\n",
    "# Replace the original data with the normalized values\n",
    "df_nodes_norm = df_nodes.copy()\n",
    "df_nodes_norm[columns_to_normalize] = normalized_data\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_nodes_norm\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T17:14:28.034053Z",
     "start_time": "2024-03-05T17:14:27.782052300Z"
    }
   },
   "id": "1833e5b7de7891d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame with node attributes and edge attributes added\n",
    "\n",
    "# Convert the DataFrame to a sparse adjacency matrix\n",
    "#A_dense = pairwise_distances(df_nodes.drop(columns=['Node']), metric='euclidean')\n",
    "A_dense = df_nodes_norm.iloc[:,5:]\n",
    "\n",
    "# Apply Louvain community detection algorithm to detect communities (if needed)\n",
    "# You may need to find an alternative community detection algorithm for DataFrame-based graphs\n",
    "\n",
    "# Calculate the modularity for different values of k\n",
    "k_values = range(1, 11)  # Adjust the range as needed\n",
    "inertias = []\n",
    "\n",
    "amount_k = len(k_values)\n",
    "for k in k_values:\n",
    "    print(f'{k}/{amount_k}')\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(A_dense)\n",
    "    inertia = kmeans.inertia_\n",
    "    inertias.append(inertia)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_values, inertias, marker='o')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal Number of Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T17:14:28.037052900Z",
     "start_time": "2024-03-05T17:14:28.036053100Z"
    }
   },
   "id": "ee5ff103f76ef046"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming df_nodes is your DataFrame containing node attributes\n",
    "\n",
    "# Extract the features (attributes) from the DataFrame\n",
    "X = df_nodes_norm.iloc[:,5:]\n",
    "\n",
    "# Specify the number of clusters (k)\n",
    "k = 4  # Adjust as needed\n",
    "\n",
    "# Initialize KMeans model\n",
    "kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Get the cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Add cluster labels as a new column in the DataFrame\n",
    "df_nodes['Cluster'] = cluster_labels\n",
    "df_nodes_norm['Cluster'] = cluster_labels\n",
    "\n",
    "# Display the DataFrame with cluster labels\n",
    "df_nodes\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T17:14:28.038053600Z"
    }
   },
   "id": "6f9289838e0fb98d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Assuming df_nodes is your DataFrame with cluster labels\n",
    "\n",
    "# Calculate the cardinality of each cluster\n",
    "cluster_cardinality = df_nodes_norm['Cluster'].value_counts()\n",
    "\n",
    "# Display the cardinality of each cluster\n",
    "print(cluster_cardinality)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-05T17:14:28.039052400Z"
    }
   },
   "id": "e88f9023d7f49d90"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
