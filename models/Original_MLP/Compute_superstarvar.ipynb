{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:51:43.479629900Z",
     "start_time": "2024-04-26T17:51:38.006631300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                       song_id  \\\n0       7kXUEJmfvRXbzxOC0pHQgb   \n1       7A131DrpfbWAfNJLrxikwf   \n2       4SRjOJm5AjO3fxXpZSTEBb   \n3       592dtCLAyLQdUallLhJinO   \n4       2hMAApqyXl7nf2s8dQ6BTv   \n...                        ...   \n911022  5ke0edZBlwRYu01wdej6xq   \n911023  12kc7hUJKpArFQurhlNeNW   \n911024  0lej8CemYKkWVHg77Xe1ky   \n911025  7goArBQdsalqclSyaTywAS   \n911026  6Fh2QgjCxL96dA3Gtpfr4Q   \n\n                                                song_name  song_popularity  \\\n0                          I Can't Believe I'm Losing You              5.0   \n1                                       Top Of The Stairs             26.0   \n2                                   Never Crossed My Mind             20.0   \n3                                              Daddy Cool              1.0   \n4                                     Shame, Shame, Shame              0.0   \n...                                                   ...              ...   \n911022                                         Let Her In              4.0   \n911023                             Stop and Think It Over              1.0   \n911024           A Man Holdin' on (To a Woman Lettin’ Go)             14.0   \n911025                                   Shimmy Shimmy Ya              7.0   \n911026  One Sweet Day (16-Bit Mariah Carey & Boyz II M...              0.0   \n\n        explicit      song_type  track_number  num_artists  \\\n0          False           Solo          12.0          1.0   \n1          False           Solo           4.0          1.0   \n2          False           Solo           3.0          1.0   \n3          False           Solo           6.0          1.0   \n4          False           Solo          15.0          1.0   \n...          ...            ...           ...          ...   \n911022     False           Solo           7.0          1.0   \n911023     False           Solo           9.0          1.0   \n911024     False  Collaboration           7.0          2.0   \n911025     False           Solo           8.0          1.0   \n911026     False           Solo          27.0          1.0   \n\n        num_available_markets release_date  duration_ms  ...  \\\n0                        79.0   1995-01-01     162667.0  ...   \n1                         2.0   1995-01-01     271307.0  ...   \n2                         2.0   1995-01-01     242027.0  ...   \n3                        79.0   1995-01-01     201307.0  ...   \n4                        79.0   1995-01-01     231973.0  ...   \n...                       ...          ...          ...  ...   \n911022                   79.0   2019-08-23     183600.0  ...   \n911023                   79.0   2019-08-23     154413.0  ...   \n911024                   79.0   2019-08-23     231898.0  ...   \n911025                   78.0   2019-08-23     161200.0  ...   \n911026                   79.0   2019-08-26     260910.0  ...   \n\n        betweenesscentrality_y  closnesscentrality_y  clustering_y  degree_y  \\\n0                          0.0              0.000000           0.0       0.0   \n1                          0.0              0.000000           0.0       0.0   \n2                          0.0              0.000000           0.0       0.0   \n3                          0.0              0.000000           0.0       0.0   \n4                          0.0              0.000000           0.0       0.0   \n...                        ...                   ...           ...       ...   \n911022                     0.0              0.000000           0.0       0.0   \n911023                     0.0              0.000000           0.0       0.0   \n911024                     0.0              0.666667           0.0       1.0   \n911025                     0.0              0.000000           0.0       0.0   \n911026                     0.0              0.000000           0.0       0.0   \n\n        eccentricity_y  eigencentrality_y  weighted degree_y  Cluster_y  \\\n0                  0.0                0.0                0.0       -1.0   \n1                  0.0                0.0                0.0       -1.0   \n2                  0.0                0.0                0.0       -1.0   \n3                  0.0                0.0                0.0       -1.0   \n4                  0.0                0.0                0.0       -1.0   \n...                ...                ...                ...        ...   \n911022             0.0                0.0                0.0       -1.0   \n911023             0.0                0.0                0.0       -1.0   \n911024             2.0                0.5                2.0        3.0   \n911025             0.0                0.0                0.0       -1.0   \n911026             0.0                0.0                0.0       -1.0   \n\n          profile_y  years_on_charts  \n0          No Match         0.000000  \n1          No Match         0.000000  \n2          No Match         0.000000  \n3          No Match         0.000000  \n4          No Match         0.000000  \n...             ...              ...  \n911022     No Match         0.383562  \n911023     No Match         0.172603  \n911024  1A 2A 3A 4A         0.191781  \n911025     No Match         0.287671  \n911026     No Match         0.517808  \n\n[911027 rows x 47 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>song_name</th>\n      <th>song_popularity</th>\n      <th>explicit</th>\n      <th>song_type</th>\n      <th>track_number</th>\n      <th>num_artists</th>\n      <th>num_available_markets</th>\n      <th>release_date</th>\n      <th>duration_ms</th>\n      <th>...</th>\n      <th>betweenesscentrality_y</th>\n      <th>closnesscentrality_y</th>\n      <th>clustering_y</th>\n      <th>degree_y</th>\n      <th>eccentricity_y</th>\n      <th>eigencentrality_y</th>\n      <th>weighted degree_y</th>\n      <th>Cluster_y</th>\n      <th>profile_y</th>\n      <th>years_on_charts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7kXUEJmfvRXbzxOC0pHQgb</td>\n      <td>I Can't Believe I'm Losing You</td>\n      <td>5.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>12.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>1995-01-01</td>\n      <td>162667.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7A131DrpfbWAfNJLrxikwf</td>\n      <td>Top Of The Stairs</td>\n      <td>26.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1995-01-01</td>\n      <td>271307.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4SRjOJm5AjO3fxXpZSTEBb</td>\n      <td>Never Crossed My Mind</td>\n      <td>20.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1995-01-01</td>\n      <td>242027.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>592dtCLAyLQdUallLhJinO</td>\n      <td>Daddy Cool</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>1995-01-01</td>\n      <td>201307.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2hMAApqyXl7nf2s8dQ6BTv</td>\n      <td>Shame, Shame, Shame</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>1995-01-01</td>\n      <td>231973.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>911022</th>\n      <td>5ke0edZBlwRYu01wdej6xq</td>\n      <td>Let Her In</td>\n      <td>4.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>7.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>2019-08-23</td>\n      <td>183600.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.383562</td>\n    </tr>\n    <tr>\n      <th>911023</th>\n      <td>12kc7hUJKpArFQurhlNeNW</td>\n      <td>Stop and Think It Over</td>\n      <td>1.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>9.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>2019-08-23</td>\n      <td>154413.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.172603</td>\n    </tr>\n    <tr>\n      <th>911024</th>\n      <td>0lej8CemYKkWVHg77Xe1ky</td>\n      <td>A Man Holdin' on (To a Woman Lettin’ Go)</td>\n      <td>14.0</td>\n      <td>False</td>\n      <td>Collaboration</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>79.0</td>\n      <td>2019-08-23</td>\n      <td>231898.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.5</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>1A 2A 3A 4A</td>\n      <td>0.191781</td>\n    </tr>\n    <tr>\n      <th>911025</th>\n      <td>7goArBQdsalqclSyaTywAS</td>\n      <td>Shimmy Shimmy Ya</td>\n      <td>7.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>78.0</td>\n      <td>2019-08-23</td>\n      <td>161200.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.287671</td>\n    </tr>\n    <tr>\n      <th>911026</th>\n      <td>6Fh2QgjCxL96dA3Gtpfr4Q</td>\n      <td>One Sweet Day (16-Bit Mariah Carey &amp; Boyz II M...</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>Solo</td>\n      <td>27.0</td>\n      <td>1.0</td>\n      <td>79.0</td>\n      <td>2019-08-26</td>\n      <td>260910.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>No Match</td>\n      <td>0.517808</td>\n    </tr>\n  </tbody>\n</table>\n<p>911027 rows × 47 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_hsp_song_collab = pd.read_csv(\"HSP_song_collab.csv\", sep=\",\")\n",
    "df_hsp_song_collab"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for Superstar:\n",
    "\n",
    "within 3 years"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4430fec788235cae"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "max_amount_days = 3*365\n",
    "max_amount_days\n",
    "\n",
    "past_years = 3"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:51:43.508629200Z",
     "start_time": "2024-04-26T17:51:43.473630300Z"
    }
   },
   "id": "ef79cc8b6e995c3e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(Timestamp('2015-08-19 23:59:59'), Timestamp('2012-08-19 23:59:59'))"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_hsp_song_collab['date'] = pd.to_datetime(df_hsp_song_collab['release_date'])\n",
    "df_hsp_song_collab.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df_hsp_song_collab, test_size=0.25, shuffle=False)\n",
    "#train_df.drop(columns=\"date\", inplace=True)\n",
    "#test_df.drop(columns=\"date\", inplace=True)\n",
    "\n",
    "present = (train_df[\"date\"].iloc[-1]).replace(hour=23, minute=59, second=59)\n",
    "present_id = train_df[\"song_id\"].iloc[-1]\n",
    "border_day = present - pd.DateOffset(years=past_years) #border day doesn't belong to the timeframe\n",
    "\n",
    "present, border_day"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:52:06.294411800Z",
     "start_time": "2024-04-26T17:52:05.314570400Z"
    }
   },
   "id": "f680972aaae5ee6a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### days and peak position:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47630050154da34"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                       song_id  rank_score  peak_position  weeks_on_chart  \\\n0       3e9HZxeyfWwjeyPAMmWSSQ         100            100               7   \n1       5p7ujcrUXASCNwRaWNHR1C          99             99              11   \n2       2xLMifQCjDGFmkHkpNLD9h          98            100              20   \n3       3KkXRkHbMCARz0aVfEt68P          97             97               9   \n4       1rqqCSm0Qe4I9rUvWncaom          95             96              20   \n...                        ...         ...            ...             ...   \n250387  6vPS75nWOKkuH5WTLD8hDc           7             23               5   \n250388  2BCjoFA0nJlXBLRf3164bN           6              6               0   \n250389  7Gk1QKi2BAZCnrYlrYEDjC           4             11               4   \n250390  7rxev6ErpRE5VYaamjs4T3           2              2               0   \n250391  1TRvdHDqCIcTQpHTZbFttC           1              1               0   \n\n             week  \n0      2018-12-29  \n1      2018-12-29  \n2      2018-12-29  \n3      2018-12-29  \n4      2018-12-29  \n...           ...  \n250387 1964-01-04  \n250388 1964-01-04  \n250389 1964-01-04  \n250390 1964-01-04  \n250391 1964-01-04  \n\n[250392 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>rank_score</th>\n      <th>peak_position</th>\n      <th>weeks_on_chart</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n      <td>100</td>\n      <td>100</td>\n      <td>7</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n      <td>99</td>\n      <td>99</td>\n      <td>11</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n      <td>98</td>\n      <td>100</td>\n      <td>20</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3KkXRkHbMCARz0aVfEt68P</td>\n      <td>97</td>\n      <td>97</td>\n      <td>9</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n      <td>95</td>\n      <td>96</td>\n      <td>20</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>250387</th>\n      <td>6vPS75nWOKkuH5WTLD8hDc</td>\n      <td>7</td>\n      <td>23</td>\n      <td>5</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250388</th>\n      <td>2BCjoFA0nJlXBLRf3164bN</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250389</th>\n      <td>7Gk1QKi2BAZCnrYlrYEDjC</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250390</th>\n      <td>7rxev6ErpRE5VYaamjs4T3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250391</th>\n      <td>1TRvdHDqCIcTQpHTZbFttC</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n  </tbody>\n</table>\n<p>250392 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_song_chart = pd.read_csv(\"../../MusicOSet/musicoset_popularity/song_chart.csv\", sep=\"\\t\")            #nur auf train daten, da rest unbekannt (für charts)\n",
    "df_song_chart['week'] = pd.to_datetime(df_song_chart['week']) #evtl später wegen runtime\n",
    "df_song_chart"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:51:55.786949400Z",
     "start_time": "2024-04-26T17:51:55.600951900Z"
    }
   },
   "id": "20650bbe3a810289"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "to_filter = df_song_chart[df_song_chart[\"song_id\"] == present_id] ## if len == 0 append 1 "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:52:08.961681400Z",
     "start_time": "2024-04-26T17:52:08.939682900Z"
    }
   },
   "id": "24813ee11b8fda90"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'>' not supported between instances of 'Timestamp' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#to_filter['week'] = pd.to_datetime(to_filter['week'])\u001B[39;00m\n\u001B[0;32m      5\u001B[0m to_filter \u001B[38;5;241m=\u001B[39m to_filter\u001B[38;5;241m.\u001B[39mto_numpy()\n\u001B[1;32m----> 6\u001B[0m to_filter \u001B[38;5;241m=\u001B[39m to_filter[(\u001B[43mto_filter\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpresent\u001B[49m) \u001B[38;5;241m&\u001B[39m (to_filter[\u001B[38;5;241m4\u001B[39m] \u001B[38;5;241m>\u001B[39m border_day)]\u001B[38;5;66;03m#pd.Timestamp(\"2015-05-02\"))] ist immer für die Vergangene Woche das chart datum?\u001B[39;00m\n\u001B[0;32m      7\u001B[0m to_filter\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\Ba_first_tries\\lib\\site-packages\\pandas\\_libs\\tslibs\\timestamps.pyx:355\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: '>' not supported between instances of 'Timestamp' and 'str'"
     ]
    }
   ],
   "source": [
    "#mit bsp id\n",
    "\n",
    "to_filter = df_song_chart[df_song_chart[\"song_id\"] == \"7yq4Qj7cqayVTp3FF9CWbm\"]#.copy()\n",
    "#to_filter['week'] = pd.to_datetime(to_filter['week'])\n",
    "to_filter = to_filter[(to_filter[\"week\"] < present) & (to_filter[\"week\"] > border_day)]#pd.Timestamp(\"2015-05-02\"))] ist immer für die Vergangene Woche das chart datum?\n",
    "to_filter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:52:53.740062500Z",
     "start_time": "2024-04-26T17:52:53.682062400Z"
    }
   },
   "id": "89c08e57f26dfe48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_peak_position = to_filter[\"peak_position\"].min()\n",
    "peak_position_index = to_filter[\"peak_position\"].idxmin()  #returns first occurance and therfore newer pos\n",
    "min_peak_position, peak_position_index #best chart placement (append)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.390812400Z"
    }
   },
   "id": "80b27f25a9fbd3b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "peak_week = to_filter.loc[peak_position_index][\"week\"]\n",
    "peak_week"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.392811100Z"
    }
   },
   "id": "de5304aecf37b85b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distance = abs(peak_week - present) #distance from peak chart placement\n",
    "distance"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.394812700Z"
    }
   },
   "id": "dd59e797e374a51f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seconds_float = distance.total_seconds()  #distance as float append"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.397811600Z"
    }
   },
   "id": "1a772b2651234628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Amount of Hits:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "940f8d1b0a109938"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "to_filter = df_song_chart.copy()\n",
    "#to_filter['week'] = pd.to_datetime(to_filter['week'])\n",
    "to_filter = to_filter[(to_filter[\"week\"] < present) & (to_filter[\"week\"] > border_day)]\n",
    "to_filter"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.399810Z"
    }
   },
   "id": "7a32411735ca3933"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_songs = pd.read_csv(\"../../MusicOSet/musicoset_metadata/songs.csv\", sep=\"\\t\")            #nur auf train daten, da rest unbekannt (für charts)\n",
    "df_songs[\"artists_ids\"] = df_songs[\"artists\"].apply(lambda x: list((eval(x)).keys()))\n",
    "df_songs = df_songs[[\"song_id\", 'artists_ids']]\n",
    "df_songs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:51:15.441808900Z",
     "start_time": "2024-04-26T17:51:15.401809700Z"
    }
   },
   "id": "5b9636af61287d21"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_songs[\"artists_ids\"].iloc[3]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.402809200Z"
    }
   },
   "id": "1bf5cbe5569ecbbe"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_num_hit = pd.merge(to_filter, df_songs)\n",
    "df_num_hit = df_num_hit.drop_duplicates(subset=[\"song_id\"])\n",
    "#df_num_hit[df_num_hit[\"artists_ids\"].apply(lambda x: len(x) > 1)]\n",
    "df_num_hit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.405810100Z"
    }
   },
   "id": "3cab5c09847cd7d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_counts = df_num_hit.groupby('song_id')['artists_ids'].apply(lambda x: list(x)).reset_index()\n",
    "df_counts[\"artists_ids\"] = df_counts[\"artists_ids\"].apply(lambda x: [set(row_list) for row_list in x ])\n",
    "#df_counts[\"artists_ids\"].apply(lambda x: [print(elt) for elt in x])\n",
    "df_counts[\"cardinality\"] = 0\n",
    "for index, id_sets in enumerate(df_counts[\"artists_ids\"]):\n",
    "    count = 0\n",
    "    if len(id_sets) > 1:\n",
    "        count +=1\n",
    "        for i in range(len(id_sets)):\n",
    "            for j in range(i+1, len(id_sets)):\n",
    "                if id_sets[i] != id_sets[j]:\n",
    "                    count += 1\n",
    "    elif len(id_sets) == 1:\n",
    "        count = 1\n",
    "    df_counts[\"cardinality\"].iloc[index] = count                    \n",
    "df_counts"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.407810200Z"
    }
   },
   "id": "e63a8c7696bf0beb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "apparently no dupliacates exist"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8826d0bebacc9dd2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_num_hit = df_num_hit[df_num_hit[\"artists_ids\"].apply(lambda x: \"17lzZA2AlOHwCwFALHttmp\" in x)] #bsp artist_id \n",
    "#amount_hits = df_num_hit[\"song_id\"].nunique()                                                              #werden identische songs mit anderen Artists seperat gezählt? (intuitive ja) include it\n",
    "#amount_hits\n",
    "df_num_hit"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.409810200Z"
    }
   },
   "id": "eae7acd129790081"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loop:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "795367ccfd6250"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.411810400Z"
    }
   },
   "id": "b28638da1c926d60"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "                       song_id  rank_score  peak_position  weeks_on_chart  \\\n0       3e9HZxeyfWwjeyPAMmWSSQ         100            100               7   \n1       5p7ujcrUXASCNwRaWNHR1C          99             99              11   \n2       2xLMifQCjDGFmkHkpNLD9h          98            100              20   \n3       3KkXRkHbMCARz0aVfEt68P          97             97               9   \n4       1rqqCSm0Qe4I9rUvWncaom          95             96              20   \n...                        ...         ...            ...             ...   \n250387  6vPS75nWOKkuH5WTLD8hDc           7             23               5   \n250388  2BCjoFA0nJlXBLRf3164bN           6              6               0   \n250389  7Gk1QKi2BAZCnrYlrYEDjC           4             11               4   \n250390  7rxev6ErpRE5VYaamjs4T3           2              2               0   \n250391  1TRvdHDqCIcTQpHTZbFttC           1              1               0   \n\n             week  \n0      2018-12-29  \n1      2018-12-29  \n2      2018-12-29  \n3      2018-12-29  \n4      2018-12-29  \n...           ...  \n250387 1964-01-04  \n250388 1964-01-04  \n250389 1964-01-04  \n250390 1964-01-04  \n250391 1964-01-04  \n\n[250392 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>rank_score</th>\n      <th>peak_position</th>\n      <th>weeks_on_chart</th>\n      <th>week</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n      <td>100</td>\n      <td>100</td>\n      <td>7</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n      <td>99</td>\n      <td>99</td>\n      <td>11</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n      <td>98</td>\n      <td>100</td>\n      <td>20</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3KkXRkHbMCARz0aVfEt68P</td>\n      <td>97</td>\n      <td>97</td>\n      <td>9</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n      <td>95</td>\n      <td>96</td>\n      <td>20</td>\n      <td>2018-12-29</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>250387</th>\n      <td>6vPS75nWOKkuH5WTLD8hDc</td>\n      <td>7</td>\n      <td>23</td>\n      <td>5</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250388</th>\n      <td>2BCjoFA0nJlXBLRf3164bN</td>\n      <td>6</td>\n      <td>6</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250389</th>\n      <td>7Gk1QKi2BAZCnrYlrYEDjC</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250390</th>\n      <td>7rxev6ErpRE5VYaamjs4T3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n    <tr>\n      <th>250391</th>\n      <td>1TRvdHDqCIcTQpHTZbFttC</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1964-01-04</td>\n    </tr>\n  </tbody>\n</table>\n<p>250392 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_song_chart = pd.read_csv(\"../../MusicOSet/musicoset_popularity/song_chart.csv\", sep=\"\\t\")            #nur auf train daten, da rest unbekannt (für charts)\n",
    "df_song_chart['week'] = pd.to_datetime(df_song_chart['week']) #evtl später wegen runtime\n",
    "df_song_chart"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:00:34.699591700Z",
     "start_time": "2024-04-26T18:00:34.548592700Z"
    }
   },
   "id": "948fa20163451baa"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                      song_id  \\\n0      3e9HZxeyfWwjeyPAMmWSSQ   \n1      5p7ujcrUXASCNwRaWNHR1C   \n2      2xLMifQCjDGFmkHkpNLD9h   \n3      3KkXRkHbMCARz0aVfEt68P   \n4      1rqqCSm0Qe4I9rUvWncaom   \n...                       ...   \n20400  4NnhLA66RRLXxKbiiscU9R   \n20401  2jHfXdCLibrI1J56LnUAZv   \n20402  6zqsyB7uIvWrL1iCJzpNrs   \n20403  5mz9pQZZXNpAw9CdQ7Bk8q   \n20404  2H9CKpZiLDF223BbwehpDF   \n\n                                            artists_ids  \n0                              [66CXWjxzNUsdJxJ2JdwvnR]  \n1                              [26VFTg2z8YR0cCuwLzESi2]  \n2                              [0Y5tJX1MQlPlqiwlOH1tJY]  \n3      [246dkjvS1zLTtiykXe5h60, 1zNqQNIdeOUZHb8zbZRFMX]  \n4                              [20JZFwl6HVl6yg8a4H3ZqK]  \n...                                                 ...  \n20400                          [5X3TuTi9OIsJXMGxPwTKM2]  \n20401                          [6lHC2EQMEMZiEmSfFloarn]  \n20402                          [5X3TuTi9OIsJXMGxPwTKM2]  \n20403                          [6lHC2EQMEMZiEmSfFloarn]  \n20404                          [6wPhSqRtPu1UhRCDX5yaDJ]  \n\n[20405 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>artists_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3e9HZxeyfWwjeyPAMmWSSQ</td>\n      <td>[66CXWjxzNUsdJxJ2JdwvnR]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5p7ujcrUXASCNwRaWNHR1C</td>\n      <td>[26VFTg2z8YR0cCuwLzESi2]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2xLMifQCjDGFmkHkpNLD9h</td>\n      <td>[0Y5tJX1MQlPlqiwlOH1tJY]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3KkXRkHbMCARz0aVfEt68P</td>\n      <td>[246dkjvS1zLTtiykXe5h60, 1zNqQNIdeOUZHb8zbZRFMX]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1rqqCSm0Qe4I9rUvWncaom</td>\n      <td>[20JZFwl6HVl6yg8a4H3ZqK]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20400</th>\n      <td>4NnhLA66RRLXxKbiiscU9R</td>\n      <td>[5X3TuTi9OIsJXMGxPwTKM2]</td>\n    </tr>\n    <tr>\n      <th>20401</th>\n      <td>2jHfXdCLibrI1J56LnUAZv</td>\n      <td>[6lHC2EQMEMZiEmSfFloarn]</td>\n    </tr>\n    <tr>\n      <th>20402</th>\n      <td>6zqsyB7uIvWrL1iCJzpNrs</td>\n      <td>[5X3TuTi9OIsJXMGxPwTKM2]</td>\n    </tr>\n    <tr>\n      <th>20403</th>\n      <td>5mz9pQZZXNpAw9CdQ7Bk8q</td>\n      <td>[6lHC2EQMEMZiEmSfFloarn]</td>\n    </tr>\n    <tr>\n      <th>20404</th>\n      <td>2H9CKpZiLDF223BbwehpDF</td>\n      <td>[6wPhSqRtPu1UhRCDX5yaDJ]</td>\n    </tr>\n  </tbody>\n</table>\n<p>20405 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs = pd.read_csv(\"../../MusicOSet/musicoset_metadata/songs.csv\", sep=\"\\t\")            #nur auf train daten, da rest unbekannt (für charts)\n",
    "df_songs[\"artists_ids\"] = df_songs[\"artists\"].apply(lambda x: list((eval(x)).keys()))\n",
    "df_songs = df_songs[[\"song_id\", 'artists_ids']]\n",
    "df_songs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:00:37.138553300Z",
     "start_time": "2024-04-26T18:00:36.895556900Z"
    }
   },
   "id": "7cacf2570ff5145b"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def superstar(n, d, p):\n",
    "    sup = 0\n",
    "    for i in range(len(d)):\n",
    "        sup += d[i] * p[i]\n",
    "    return 1/n**2 * sup\n",
    "\n",
    "superstar(1, [1], [1])      #kommt es in produktivcode vor? wie mit nicht vorkommenden Werten umgehen?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:00:40.641539600Z",
     "start_time": "2024-04-26T18:00:40.605541800Z"
    }
   },
   "id": "b5ff8ba811c4dfbd"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "([0.0, 0.24242424242424243, 0.494949494949495, 0.7474747474747475, 1.0],\n [0.0, 0.25, 0.5, 0.75, 1.0])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_max_scaling(arr, min_val, max_val):\n",
    "    return [(x - min_val)/(max_val - min_val) for x in arr]\n",
    "\n",
    "past_years = 3\n",
    "max_amount_days = past_years*365\n",
    "max_distance_float = max_amount_days*24*60*60\n",
    "\n",
    "peak_positions = [1, 25, 50, 75, 100]\n",
    "days_distances = [0.00, max_distance_float*0.25, max_distance_float*0.5, max_distance_float*0.75, max_distance_float]\n",
    "peak_positions = min_max_scaling(peak_positions, 1, 100) #101 oder 100 als edge\n",
    "days_distances = min_max_scaling(days_distances, 0.00, max_distance_float)\n",
    "peak_positions, days_distances"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:00:41.136114900Z",
     "start_time": "2024-04-26T18:00:41.112113400Z"
    }
   },
   "id": "89dc6a7b881f4ce7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "past_years = 3\n",
    "max_amount_days = past_years * 365\n",
    "max_distance_float = max_amount_days * 24 * 60 * 60\n",
    "\n",
    "train_df[\"superstar_v1_x\"] = 1.0\n",
    "train_df[\"superstar_v1_y\"] = np.nan\n",
    "\n",
    "it = 0\n",
    "for index, row in train_df.iterrows():\n",
    "    artists_in_row = [row[\"artist1_id\"]]\n",
    "    if not pd.isna(row[\"artist2_id\"]):\n",
    "        artists_in_row.append(row[\"artist2_id\"])\n",
    "\n",
    "    print(it)\n",
    "    it +=1\n",
    "\n",
    "    present = row[\"date\"].replace(hour=23, minute=59, second=59)\n",
    "    border_day = present - pd.DateOffset(years=past_years)\n",
    "    to_filter = df_song_chart[(df_song_chart[\"week\"] <= present) & (df_song_chart[\"week\"] > border_day)]\n",
    "\n",
    "    for nr_art, artist in enumerate(artists_in_row):\n",
    "        hits_amount = 0\n",
    "        song_ids = []\n",
    "        peak_positions = []\n",
    "        days_distances = []\n",
    "\n",
    "        df_num_hit = pd.merge(to_filter, df_songs)\n",
    "        df_num_hit_cpy = df_num_hit.copy()\n",
    "        if not df_num_hit.empty:\n",
    "            df_num_hit = df_num_hit.drop_duplicates(subset=[\"song_id\"])\n",
    "            df_num_hit = df_num_hit[df_num_hit[\"artists_ids\"].apply(lambda x: artist in x)]\n",
    "\n",
    "            hits_amount = df_num_hit[\"song_id\"].nunique()\n",
    "            song_ids = df_num_hit[\"song_id\"].tolist()\n",
    "\n",
    "            #insert rest of calc here\n",
    "            if hits_amount > 0:\n",
    "                for song_id in song_ids:\n",
    "                    df_song_peak_days = df_num_hit_cpy[df_num_hit_cpy[\"song_id\"] == song_id]\n",
    "                    min_peak_position = df_song_peak_days[\"peak_position\"].min()\n",
    "                    peak_positions.append(min_peak_position)\n",
    "    \n",
    "                    peak_week = df_song_peak_days.loc[df_song_peak_days[\"peak_position\"].idxmin()][\"week\"]\n",
    "                    distance = abs(peak_week - present)\n",
    "                    days_distances.append(distance.total_seconds())\n",
    "    \n",
    "                peak_positions = min_max_scaling(peak_positions, 1, 100)\n",
    "                days_distances = min_max_scaling(days_distances, 0.00, max_distance_float)\n",
    "    \n",
    "                if nr_art == 0:\n",
    "                    train_df.loc[index, \"superstar_v1_x\"] = superstar(hits_amount, peak_positions, days_distances)\n",
    "                elif nr_art == 1:\n",
    "                    train_df.loc[index, \"superstar_v1_y\"] = superstar(hits_amount, peak_positions, days_distances)\n",
    "                print(str(nr_art) + \":   \" + str(superstar(hits_amount, peak_positions, days_distances)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.422809600Z"
    }
   },
   "id": "3986d58bb9d6a9a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(683270/30636) *  5  +1.8586 # runtime "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.424808600Z"
    }
   },
   "id": "b53639dd3a73950c"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([['7kXUEJmfvRXbzxOC0pHQgb', \"I Can't Believe I'm Losing You\", 5.0,\n        ..., Timestamp('1995-01-01 00:00:00'), 1.0, nan],\n       ['5pedBzuqzuqb8NPXqXFm1T',\n        'Song To The Siren - Live From Sabresonic Nightclub,United Kingdom/1994',\n        35.0, ..., Timestamp('1995-01-01 00:00:00'), 1.0, nan],\n       ['7E89BPSPTtBaR9mKK88WhD', 'Three Little Birdies Down Beats',\n        30.0, ..., Timestamp('1995-01-01 00:00:00'), 1.0, nan],\n       ...,\n       ['0gvKPCmhJzXa4YgptrNvI4', 'Up the Hill', 0.0, ...,\n        Timestamp('2015-08-19 00:00:00'), 1.0, nan],\n       ['5FDxZkCXwOOO0CQP3zQUBL',\n        '浪花恋しぐれ Originally Performed By 都はるみ・岡千秋 (オルゴール)', 0.0, ...,\n        Timestamp('2015-08-19 00:00:00'), 1.0, nan],\n       ['3m3CVlgUzXQaFkXdMPV3nI',\n        'バス・ストップ Originally Performed By 平浩二 (オルゴール)', 1.0, ...,\n        Timestamp('2015-08-19 00:00:00'), 1.0, nan]], dtype=object)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_df[\"superstar_v1_x\"] = 1.0\n",
    "train_df[\"superstar_v1_y\"] = np.nan\n",
    "# Assuming train_df is your pandas DataFrame\n",
    "train_np_array = train_df.to_numpy()\n",
    "train_np_array"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:54:48.911421600Z",
     "start_time": "2024-04-26T17:54:46.939423Z"
    }
   },
   "id": "a77170642862eb4f"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'song_id': 0,\n 'song_name': 1,\n 'song_popularity': 2,\n 'explicit': 3,\n 'song_type': 4,\n 'track_number': 5,\n 'num_artists': 6,\n 'num_available_markets': 7,\n 'release_date': 8,\n 'duration_ms': 9,\n 'key': 10,\n 'mode': 11,\n 'time_signature': 12,\n 'acousticness': 13,\n 'danceability': 14,\n 'energy': 15,\n 'instrumentalness': 16,\n 'liveness': 17,\n 'loudness': 18,\n 'speechiness': 19,\n 'valence': 20,\n 'tempo': 21,\n 'hit': 22,\n 'nr_artists': 23,\n 'artist1_id': 24,\n 'artist2_id': 25,\n 'name_x': 26,\n 'betweenesscentrality_x': 27,\n 'closnesscentrality_x': 28,\n 'clustering_x': 29,\n 'degree_x': 30,\n 'eccentricity_x': 31,\n 'eigencentrality_x': 32,\n 'weighted degree_x': 33,\n 'Cluster_x': 34,\n 'profile_x': 35,\n 'name_y': 36,\n 'betweenesscentrality_y': 37,\n 'closnesscentrality_y': 38,\n 'clustering_y': 39,\n 'degree_y': 40,\n 'eccentricity_y': 41,\n 'eigencentrality_y': 42,\n 'weighted degree_y': 43,\n 'Cluster_y': 44,\n 'profile_y': 45,\n 'years_on_charts': 46,\n 'date': 47,\n 'superstar_v1_x': 48,\n 'superstar_v1_y': 49}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = train_df.columns\n",
    "# Assuming train_np_array is your NumPy array and column_names is a list containing the column names in the same order as they appear in train_np_array\n",
    "\n",
    "column_name_to_index = {name: index for index, name in enumerate(column_names)}\n",
    "column_name_to_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T17:54:52.307421800Z",
     "start_time": "2024-04-26T17:54:52.233422500Z"
    }
   },
   "id": "a2882a301788f16f"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "{'song_id': 0,\n 'rank_score': 1,\n 'peak_position': 2,\n 'weeks_on_chart': 3,\n 'week': 4}"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_chart_np = df_song_chart.to_numpy() \n",
    "column_names_song_charts = df_song_chart.columns\n",
    "# Assuming train_np_array is your NumPy array and column_names is a list containing the column names in the same order as they appear in train_np_array\n",
    "\n",
    "column_index_song_chart = {name: index for index, name in enumerate(column_names_song_charts)}\n",
    "column_index_song_chart"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:43:33.551047800Z",
     "start_time": "2024-04-26T18:43:33.394048400Z"
    }
   },
   "id": "b7c93946f6d44fe9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "song_np = df_songs.to_numpy()\n",
    "column_names = df_songs.columns\n",
    "# Assuming train_np_array is your NumPy array and column_names is a list containing the column names in the same order as they appear in train_np_array\n",
    "\n",
    "column_index_songs = {name: index for index, name in enumerate(column_names)}\n",
    "column_index_songs"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e4742e476d838e"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n",
      "[]\n",
      "1\n",
      "[]\n",
      "[]\n",
      "2\n",
      "[]\n",
      "[]\n",
      "3\n",
      "[]\n",
      "[]\n",
      "4\n",
      "[]\n",
      "[]\n",
      "5\n",
      "[]\n",
      "[]\n",
      "6\n",
      "[]\n",
      "[]\n",
      "7\n",
      "[]\n",
      "[]\n",
      "8\n",
      "[]\n",
      "[]\n",
      "9\n",
      "[]\n",
      "[]\n",
      "10\n",
      "[]\n",
      "[]\n",
      "11\n",
      "[]\n",
      "[]\n",
      "12\n",
      "[]\n",
      "[]\n",
      "13\n",
      "[]\n",
      "[]\n",
      "14\n",
      "[]\n",
      "[]\n",
      "15\n",
      "[]\n",
      "[]\n",
      "16\n",
      "[]\n",
      "[]\n",
      "17\n",
      "[]\n",
      "[]\n",
      "18\n",
      "[]\n",
      "[]\n",
      "19\n",
      "[]\n",
      "[]\n",
      "20\n",
      "[]\n",
      "[]\n",
      "21\n",
      "[]\n",
      "[]\n",
      "22\n",
      "[]\n",
      "[]\n",
      "23\n",
      "[]\n",
      "[]\n",
      "24\n",
      "[]\n",
      "[]\n",
      "25\n",
      "[]\n",
      "[]\n",
      "26\n",
      "[]\n",
      "[]\n",
      "27\n",
      "[]\n",
      "[]\n",
      "28\n",
      "[]\n",
      "[]\n",
      "29\n",
      "[]\n",
      "[]\n",
      "30\n",
      "[]\n",
      "[]\n",
      "31\n",
      "[]\n",
      "[]\n",
      "32\n",
      "[]\n",
      "[]\n",
      "33\n",
      "[]\n",
      "[]\n",
      "34\n",
      "[]\n",
      "[]\n",
      "35\n",
      "[]\n",
      "[]\n",
      "36\n",
      "[]\n",
      "[]\n",
      "37\n",
      "[]\n",
      "[]\n",
      "38\n",
      "[]\n",
      "[]\n",
      "39\n",
      "[]\n",
      "[]\n",
      "40\n",
      "[]\n",
      "[]\n",
      "41\n",
      "[]\n",
      "[]\n",
      "42\n",
      "[]\n",
      "[]\n",
      "43\n",
      "[]\n",
      "[]\n",
      "44\n",
      "[]\n",
      "[]\n",
      "45\n",
      "[]\n",
      "[]\n",
      "46\n",
      "[]\n",
      "[]\n",
      "47\n",
      "[]\n",
      "[]\n",
      "48\n",
      "[]\n",
      "[]\n",
      "49\n",
      "[]\n",
      "[]\n",
      "50\n",
      "[]\n",
      "[]\n",
      "51\n",
      "[]\n",
      "[]\n",
      "52\n",
      "[]\n",
      "[]\n",
      "53\n",
      "[]\n",
      "[]\n",
      "54\n",
      "[]\n",
      "[]\n",
      "55\n",
      "[]\n",
      "[]\n",
      "56\n",
      "[]\n",
      "[]\n",
      "57\n",
      "[]\n",
      "[]\n",
      "58\n",
      "[]\n",
      "[]\n",
      "59\n",
      "[]\n",
      "[]\n",
      "60\n",
      "[]\n",
      "[]\n",
      "61\n",
      "[]\n",
      "[]\n",
      "62\n",
      "[]\n",
      "[]\n",
      "63\n",
      "[]\n",
      "[]\n",
      "64\n",
      "[]\n",
      "[]\n",
      "65\n",
      "[]\n",
      "[]\n",
      "66\n",
      "[]\n",
      "[]\n",
      "67\n",
      "[]\n",
      "[]\n",
      "68\n",
      "[]\n",
      "[]\n",
      "69\n",
      "[]\n",
      "[]\n",
      "70\n",
      "[]\n",
      "[]\n",
      "71\n",
      "[]\n",
      "[]\n",
      "72\n",
      "[]\n",
      "[]\n",
      "73\n",
      "[]\n",
      "[]\n",
      "74\n",
      "[]\n",
      "[]\n",
      "75\n",
      "[]\n",
      "[]\n",
      "76\n",
      "[]\n",
      "[]\n",
      "77\n",
      "[]\n",
      "[]\n",
      "78\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "79\n",
      "[]\n",
      "[]\n",
      "80\n",
      "[]\n",
      "[]\n",
      "81\n",
      "[]\n",
      "[]\n",
      "82\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "83\n",
      "[]\n",
      "[]\n",
      "84\n",
      "[]\n",
      "[]\n",
      "85\n",
      "[]\n",
      "[]\n",
      "86\n",
      "[]\n",
      "[]\n",
      "87\n",
      "[]\n",
      "[]\n",
      "88\n",
      "[]\n",
      "[]\n",
      "89\n",
      "[]\n",
      "[]\n",
      "90\n",
      "[]\n",
      "[]\n",
      "91\n",
      "[]\n",
      "[]\n",
      "92\n",
      "[]\n",
      "[]\n",
      "93\n",
      "[]\n",
      "[]\n",
      "94\n",
      "[]\n",
      "[]\n",
      "95\n",
      "[]\n",
      "[]\n",
      "96\n",
      "[]\n",
      "[]\n",
      "97\n",
      "[]\n",
      "[]\n",
      "98\n",
      "[]\n",
      "[]\n",
      "99\n",
      "[]\n",
      "[]\n",
      "100\n",
      "[]\n",
      "[]\n",
      "101\n",
      "[]\n",
      "[]\n",
      "102\n",
      "[]\n",
      "[]\n",
      "103\n",
      "[]\n",
      "[]\n",
      "104\n",
      "[]\n",
      "[]\n",
      "105\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "106\n",
      "[]\n",
      "[]\n",
      "107\n",
      "[]\n",
      "[]\n",
      "108\n",
      "[]\n",
      "[]\n",
      "109\n",
      "[]\n",
      "[]\n",
      "110\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "111\n",
      "[]\n",
      "[]\n",
      "112\n",
      "[]\n",
      "[]\n",
      "113\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "114\n",
      "[]\n",
      "[]\n",
      "115\n",
      "[]\n",
      "[]\n",
      "116\n",
      "[]\n",
      "[]\n",
      "117\n",
      "[]\n",
      "[]\n",
      "118\n",
      "[]\n",
      "[]\n",
      "119\n",
      "[]\n",
      "[]\n",
      "120\n",
      "[]\n",
      "[]\n",
      "121\n",
      "[]\n",
      "[]\n",
      "122\n",
      "[]\n",
      "[]\n",
      "123\n",
      "[]\n",
      "[]\n",
      "124\n",
      "[]\n",
      "[]\n",
      "125\n",
      "[]\n",
      "[]\n",
      "126\n",
      "[]\n",
      "[]\n",
      "127\n",
      "[]\n",
      "[]\n",
      "128\n",
      "[]\n",
      "[]\n",
      "129\n",
      "[]\n",
      "[]\n",
      "130\n",
      "[]\n",
      "[]\n",
      "131\n",
      "[]\n",
      "[]\n",
      "132\n",
      "[]\n",
      "[]\n",
      "133\n",
      "[]\n",
      "[]\n",
      "134\n",
      "[]\n",
      "[]\n",
      "135\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "136\n",
      "[]\n",
      "[]\n",
      "137\n",
      "[]\n",
      "[]\n",
      "138\n",
      "[]\n",
      "[]\n",
      "139\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "140\n",
      "[]\n",
      "[]\n",
      "141\n",
      "[]\n",
      "[]\n",
      "142\n",
      "[]\n",
      "[]\n",
      "143\n",
      "[]\n",
      "[]\n",
      "144\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "145\n",
      "[]\n",
      "[]\n",
      "146\n",
      "[]\n",
      "[]\n",
      "147\n",
      "[]\n",
      "[]\n",
      "148\n",
      "[]\n",
      "[]\n",
      "149\n",
      "[]\n",
      "[]\n",
      "150\n",
      "[]\n",
      "[]\n",
      "151\n",
      "[]\n",
      "[]\n",
      "152\n",
      "[]\n",
      "[]\n",
      "153\n",
      "[]\n",
      "[]\n",
      "154\n",
      "[]\n",
      "[]\n",
      "155\n",
      "[]\n",
      "[]\n",
      "156\n",
      "[]\n",
      "[]\n",
      "157\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "158\n",
      "[]\n",
      "[]\n",
      "159\n",
      "[]\n",
      "[]\n",
      "160\n",
      "[]\n",
      "[]\n",
      "161\n",
      "[]\n",
      "[]\n",
      "162\n",
      "[]\n",
      "[]\n",
      "163\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "164\n",
      "[]\n",
      "[]\n",
      "165\n",
      "[]\n",
      "[]\n",
      "166\n",
      "[]\n",
      "[]\n",
      "167\n",
      "[]\n",
      "[]\n",
      "168\n",
      "[]\n",
      "[]\n",
      "169\n",
      "[]\n",
      "[]\n",
      "170\n",
      "[]\n",
      "[]\n",
      "171\n",
      "[]\n",
      "[]\n",
      "172\n",
      "[]\n",
      "[]\n",
      "173\n",
      "[]\n",
      "[]\n",
      "174\n",
      "[]\n",
      "[]\n",
      "175\n",
      "[]\n",
      "[]\n",
      "176\n",
      "[]\n",
      "[]\n",
      "177\n",
      "[]\n",
      "[]\n",
      "178\n",
      "[]\n",
      "[]\n",
      "179\n",
      "[]\n",
      "[]\n",
      "180\n",
      "[]\n",
      "[]\n",
      "181\n",
      "[]\n",
      "[]\n",
      "182\n",
      "[]\n",
      "[]\n",
      "183\n",
      "[]\n",
      "[]\n",
      "184\n",
      "[]\n",
      "[]\n",
      "185\n",
      "[]\n",
      "[]\n",
      "186\n",
      "[]\n",
      "[]\n",
      "187\n",
      "[]\n",
      "[]\n",
      "188\n",
      "[]\n",
      "[]\n",
      "189\n",
      "[]\n",
      "[]\n",
      "190\n",
      "[]\n",
      "[]\n",
      "191\n",
      "[]\n",
      "[]\n",
      "192\n",
      "[]\n",
      "[]\n",
      "193\n",
      "[]\n",
      "[]\n",
      "194\n",
      "[]\n",
      "[]\n",
      "195\n",
      "[]\n",
      "[]\n",
      "196\n",
      "[]\n",
      "[]\n",
      "197\n",
      "[]\n",
      "[]\n",
      "198\n",
      "[]\n",
      "[]\n",
      "199\n",
      "[]\n",
      "[]\n",
      "200\n",
      "[]\n",
      "[]\n",
      "201\n",
      "[]\n",
      "[]\n",
      "202\n",
      "[]\n",
      "[]\n",
      "203\n",
      "[]\n",
      "[]\n",
      "204\n",
      "[]\n",
      "[]\n",
      "205\n",
      "[]\n",
      "[]\n",
      "206\n",
      "[]\n",
      "[]\n",
      "207\n",
      "[]\n",
      "[]\n",
      "208\n",
      "[]\n",
      "[]\n",
      "209\n",
      "[]\n",
      "[]\n",
      "210\n",
      "[]\n",
      "[]\n",
      "211\n",
      "[]\n",
      "[]\n",
      "212\n",
      "[]\n",
      "[]\n",
      "213\n",
      "[]\n",
      "[]\n",
      "214\n",
      "[]\n",
      "[]\n",
      "215\n",
      "[]\n",
      "[]\n",
      "216\n",
      "[]\n",
      "[]\n",
      "217\n",
      "[]\n",
      "[]\n",
      "218\n",
      "[]\n",
      "[]\n",
      "219\n",
      "[]\n",
      "[]\n",
      "220\n",
      "[]\n",
      "[]\n",
      "221\n",
      "[]\n",
      "[]\n",
      "222\n",
      "[]\n",
      "[]\n",
      "223\n",
      "[]\n",
      "[]\n",
      "224\n",
      "[]\n",
      "[]\n",
      "225\n",
      "[]\n",
      "[]\n",
      "226\n",
      "[]\n",
      "[]\n",
      "227\n",
      "[]\n",
      "[]\n",
      "228\n",
      "[]\n",
      "[]\n",
      "229\n",
      "[]\n",
      "[]\n",
      "230\n",
      "[]\n",
      "[]\n",
      "231\n",
      "[]\n",
      "[]\n",
      "232\n",
      "[]\n",
      "[]\n",
      "233\n",
      "[]\n",
      "[]\n",
      "234\n",
      "[]\n",
      "[]\n",
      "235\n",
      "[]\n",
      "[]\n",
      "236\n",
      "[]\n",
      "[]\n",
      "237\n",
      "[]\n",
      "[]\n",
      "238\n",
      "[]\n",
      "[]\n",
      "239\n",
      "[]\n",
      "[]\n",
      "240\n",
      "[]\n",
      "[]\n",
      "241\n",
      "[]\n",
      "[]\n",
      "242\n",
      "[]\n",
      "[]\n",
      "243\n",
      "[]\n",
      "[]\n",
      "244\n",
      "[]\n",
      "[]\n",
      "245\n",
      "[]\n",
      "[]\n",
      "246\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "247\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "248\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "249\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "250\n",
      "[]\n",
      "[]\n",
      "251\n",
      "[]\n",
      "[]\n",
      "252\n",
      "[]\n",
      "[]\n",
      "253\n",
      "[]\n",
      "[]\n",
      "254\n",
      "[]\n",
      "[]\n",
      "255\n",
      "[]\n",
      "[]\n",
      "256\n",
      "[]\n",
      "[]\n",
      "257\n",
      "[]\n",
      "[]\n",
      "258\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m present \u001B[38;5;241m=\u001B[39m row[column_name_to_index[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdate\u001B[39m\u001B[38;5;124m\"\u001B[39m]]\u001B[38;5;241m.\u001B[39mreplace(hour\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m23\u001B[39m, minute\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m59\u001B[39m, second\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m59\u001B[39m)  \u001B[38;5;66;03m# Replace date_index with the index of the date column\u001B[39;00m\n\u001B[0;32m     22\u001B[0m border_day \u001B[38;5;241m=\u001B[39m present \u001B[38;5;241m-\u001B[39m pd\u001B[38;5;241m.\u001B[39mDateOffset(years\u001B[38;5;241m=\u001B[39mpast_years)\n\u001B[1;32m---> 23\u001B[0m to_filter \u001B[38;5;241m=\u001B[39m \u001B[43msong_chart_np\u001B[49m\u001B[43m[\u001B[49m\u001B[43m(\u001B[49m\u001B[43msong_chart_np\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_index_song_chart\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweek\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m<\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpresent\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msong_chart_np\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumn_index_song_chart\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweek\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mborder_day\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m  \u001B[38;5;66;03m# Replace week_index with the index of the week column\u001B[39;00m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m nr_art, artist \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(artists_in_row):\n\u001B[0;32m     26\u001B[0m     hits_amount \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming train_np_array is your NumPy array\n",
    "\n",
    "past_years = 3\n",
    "max_amount_days = past_years * 365\n",
    "max_distance_float = max_amount_days * 24 * 60 * 60\n",
    "\n",
    "# Create columns for superstar_v1_x and superstar_v1_y\n",
    "#train_np_array = np.column_stack((train_np_array, np.full(len(train_np_array), 1.0), np.full(len(train_np_array), np.nan)))\n",
    "\n",
    "it = 0\n",
    "for row in train_np_array:\n",
    "    artists_in_row = [row[column_name_to_index[\"artist1_id\"]]]  # Replace artist1_id_index with the index of the artist1_id column\n",
    "    if pd.notna(row[column_name_to_index[\"artist2_id\"]]):  # Replace artist2_id_index with the index of the artist2_id column\n",
    "        artists_in_row.append(row[column_name_to_index[\"artist2_id\"]])\n",
    "\n",
    "    print(it)\n",
    "    it += 1\n",
    "\n",
    "    present = row[column_name_to_index[\"date\"]].replace(hour=23, minute=59, second=59)  # Replace date_index with the index of the date column\n",
    "    border_day = present - pd.DateOffset(years=past_years)\n",
    "    to_filter = song_chart_np[(song_chart_np[:, column_index_song_chart[\"week\"]] <= present) & (song_chart_np[:, column_index_song_chart[\"week\"]] > border_day)]  # Replace week_index with the index of the week column\n",
    "\n",
    "    for nr_art, artist in enumerate(artists_in_row):\n",
    "        hits_amount = 0\n",
    "        song_ids = []\n",
    "        peak_positions = []\n",
    "        days_distances = []\n",
    "\n",
    "        df_num_hit = pd.merge(pd.DataFrame(to_filter, columns=column_names_song_charts), df_songs)  # Assuming df_songs is your NumPy array\n",
    "        np_num_hits = df_num_hit.to_numpy()\n",
    "        column_names = df_num_hit.columns\n",
    "        # Assuming train_np_array is your NumPy array and column_names is a list containing the column names in the same order as they appear in train_np_array\n",
    "        \n",
    "        column_index_num_hits = {name: index for index, name in enumerate(column_names)}\n",
    "        np_num_hits_cpy = np_num_hits.copy()\n",
    "        if not np_num_hits.size == 0:\n",
    "            #print(np_num_hits_cpy)\n",
    "            # Convert the object array to a DataFrame\n",
    "            df_num_hits = pd.DataFrame(np_num_hits, columns=column_names)\n",
    "            \n",
    "            # Perform the unique operation on the DataFrame\n",
    "            df_num_hits_unique = df_num_hits.drop_duplicates(subset=[\"song_id\"])  # Assuming \"song_id\" is the column name for the key\n",
    "            #print(df_num_hits_unique)\n",
    "            # Convert back to a NumPy array if needed\n",
    "            np_num_hits = df_num_hits_unique.to_numpy()\n",
    "\n",
    "            np_between = np_num_hits[:, column_index_num_hits[\"artists_ids\"]]\n",
    "            # if np_between.ndim == 1:\n",
    "            #     np_between = np_between.reshape(-1, 1)\n",
    "            #np_num_hits = np_num_hits[np.unique(np_num_hits[:, column_index_num_hits[\"song_id\"]], axis=0)]  # Replace song_id_index with the index of the song_id column\n",
    "            np_num_hits = np_num_hits[np.apply_along_axis(lambda x: artist in x, axis=0, arr=np_between)]  # Replace artists_ids_index with the index of the artists_ids column\n",
    "            print(np_num_hits)\n",
    "            hits_amount = np_num_hits.size #np.unique(np_num_hits[:, column_index_num_hits[\"song_id\"]]).size\n",
    "            song_ids = np_num_hits[:, column_index_num_hits[\"song_id\"]].tolist()\n",
    "            print(song_ids)\n",
    "            # insert rest of calc here\n",
    "            if hits_amount > 0:\n",
    "                for song_id in song_ids:\n",
    "                    df_song_peak_days = np_num_hits_cpy[np_num_hits_cpy[:, column_index_num_hits[\"song_id\"]] == song_id]\n",
    "                    min_peak_position = np.min(df_song_peak_days[:, column_index_num_hits[\"peak_position\"]])\n",
    "                    peak_positions.append(min_peak_position)\n",
    "\n",
    "                    peak_week = df_song_peak_days[np.argmin(df_song_peak_days[:, column_index_num_hits[\"peak_position\"]]), column_index_num_hits[\"week\"]]\n",
    "                    distance = abs(peak_week - present)\n",
    "                    days_distances.append(distance.total_seconds())\n",
    "\n",
    "                peak_positions = min_max_scaling(peak_positions, 1, 100)\n",
    "                days_distances = min_max_scaling(days_distances, 0.00, max_distance_float)\n",
    "\n",
    "                if nr_art == 0:\n",
    "                    row[column_name_to_index[\"superstar_v1_x\"]] = superstar(hits_amount, peak_positions, days_distances)  # Replace superstar_v1_x_index with the index of the superstar_v1_x column\n",
    "                elif nr_art == 1:\n",
    "                    row[column_name_to_index[\"superstar_v1_y\"]] = superstar(hits_amount, peak_positions, days_distances)  # Replace superstar_v1_y_index with the index of the superstar_v1_y column\n",
    "                print(str(nr_art) + \":   \" + str(superstar(hits_amount, peak_positions, days_distances)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:46:42.554031200Z",
     "start_time": "2024-04-26T18:46:15.497149600Z"
    }
   },
   "id": "8a4f804f409a293c"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "'6O74knDqdv3XaWtkII7Xjp'"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_num_hits[0, column_index_num_hits[\"artists_ids\"]][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:27:08.079600800Z",
     "start_time": "2024-04-26T18:27:08.062601200Z"
    }
   },
   "id": "a1360297a230ccca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train_df_superstar_v1_0.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.430808900Z"
    }
   },
   "id": "8ced032ed41ff018"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_df[\"superstar_native_x\"] = 0\n",
    "train_df[\"superstar_native_y\"] = np.nan"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-26T17:51:15.431809100Z"
    }
   },
   "id": "5e96f643787c916a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50f56934c1a1e8c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
