{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data = pd.read_csv(\"data_superstar_v1_0_original_netmet.csv\", delimiter=\",\")\n",
    "data['date'] = pd.to_datetime(data['release_date'])\n",
    "data.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "\n",
    "# Drop columns not in the list\n",
    "data[\"explicit\"] = data[\"explicit\"].astype(int)\n",
    "\n",
    "\n",
    "def find_min_max(df):\n",
    "    # Select only numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number'])\n",
    "\n",
    "    # Find max and min values for each numeric column\n",
    "    min_max_values = {}\n",
    "    for col in numeric_cols.columns:\n",
    "        min_value = df[col].min()\n",
    "        max_value = df[col].max()\n",
    "        min_max_values[col] = {'min': min_value, 'max': max_value}\n",
    "\n",
    "    return min_max_values\n",
    "\n",
    "\n",
    "min_max_val = find_min_max(data)\n",
    "\n",
    "y = data[\"hit\"]\n",
    "X = data.drop(columns=[\"hit\", \"song_popularity\", \"date\", \"name_x\", \"name_y\", \"song_id\", \"song_name\", \"artist1_id\", \"artist2_id\", \"song_type\"])#, \"years_on_charts\"])\n",
    "\n",
    "\n",
    "def preprocess(df, min_max_values, exclude_cols=None):\n",
    "    missing_numerical = df.select_dtypes(include=['number']).isnull().sum()\n",
    "    # Fill missing values with mean for each numeric attribute\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_filled = df.copy()\n",
    "    for col in missing_numerical.index:\n",
    "        if missing_numerical[col] > 0:\n",
    "            df_filled[col] = imputer.fit_transform(df[[col]])\n",
    "\n",
    "    # Normalize numerical features into [0, 1] range with MinMaxScaler\n",
    "    if exclude_cols:\n",
    "        numerical_cols = df_filled.select_dtypes(include=['number']).columns.difference(exclude_cols)\n",
    "    else:\n",
    "        numerical_cols = df_filled.select_dtypes(include=['number']).columns\n",
    "\n",
    "    # print(\"numerical columns:\", numerical_cols)\n",
    "\n",
    "    for column_name in numerical_cols:\n",
    "        df_filled[column_name] = (df_filled[column_name] - min_max_values[column_name][\"min\"]) / (\n",
    "                min_max_values[column_name][\"max\"] - min_max_values[column_name][\"min\"])\n",
    "\n",
    "    df_normalized = pd.DataFrame(df_filled, columns=numerical_cols)\n",
    "\n",
    "    if exclude_cols:\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns.difference(exclude_cols)\n",
    "    else:\n",
    "        categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)     #questionable whether true or false\n",
    "\n",
    "    encoded_columns = [col for col in df_encoded.columns if any(orig_col in col for orig_col in categorical_cols)]\n",
    "\n",
    "    #print(categorical_cols)\n",
    "\n",
    "    # Concatenate numerical and encoded categorical features\n",
    "    df_processed = pd.concat([df_normalized, df_encoded[encoded_columns], df[exclude_cols]], axis=1)\n",
    "\n",
    "    return df_processed\n",
    "\n",
    "\n",
    "\n",
    "X_preprocessed = preprocess(X, min_max_val, exclude_cols=[\"release_date\"])\n",
    "X_preprocessed[X_preprocessed.select_dtypes(include=[bool]).columns] = X_preprocessed.select_dtypes(include=[bool]).astype(int)\n",
    "\n",
    "# split_day = X[\"date\"].iloc[-1] - pd.DateOffset(years=1)\n",
    "# X_train = X[(X[\"date\"] < split_day)].copy()\n",
    "# X_test = X[(X[\"date\"] >= split_day)].copy()\n",
    "# \n",
    "# sep_index = X_train.shape[0]\n",
    "# y_train = y.iloc[:sep_index].copy()\n",
    "# y_test = y.iloc[sep_index:].copy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.25, shuffle=False)\n",
    "\n",
    "feature_names = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def upsampling(X_train, y_train):\n",
    "    # Convert y_train to a numpy array\n",
    "    # y_train = y_train.to_numpy()\n",
    "    X_train = X_train.to_numpy()\n",
    "\n",
    "    # Count the number of samples in each class\n",
    "    class_counts = np.bincount(y_train.flatten().astype(int))\n",
    "    max_count = class_counts.max()\n",
    "\n",
    "    # Find indices of positive instances\n",
    "    positive_indices = np.where(y_train.flatten() == 1)[0]\n",
    "\n",
    "    # Calculate how many times to duplicate positive samples\n",
    "    difference = max_count - class_counts[1]\n",
    "\n",
    "    # Randomly select indices from positive instances\n",
    "    random_indices = np.random.choice(positive_indices, size=difference, replace=True)\n",
    "\n",
    "    # Get rows corresponding to positive instances\n",
    "    rows_to_duplicate = np.vstack([X_train[idx] for idx in random_indices])\n",
    "\n",
    "    # Stack duplicated rows with the original matrix\n",
    "    X_train_upsampled = np.vstack([X_train, rows_to_duplicate])\n",
    "\n",
    "    # Create an array of shape (x, 1) with all elements as 1\n",
    "    rows_of_ones = np.ones((difference, 1))\n",
    "\n",
    "    # Append rows_of_ones to original_array\n",
    "    y_train_upsampled = np.concatenate((y_train, rows_of_ones), axis=0)\n",
    "\n",
    "    print(\"######UPSAMPLING DONE######\")\n",
    "    return X_train_upsampled, y_train_upsampled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2777d9c34ad37c3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, y_train = upsampling(X_train, y_train.values.reshape(-1, 1))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32786eaa881df7da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=feature_names)\n",
    "y_train_df = pd.DataFrame(y_train, columns=[\"hit\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfc746703edf060f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_upsampled_with_y = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "X_train_upsampled_with_y['date'] = pd.to_datetime(X_train_upsampled_with_y['release_date'])\n",
    "X_train_upsampled_with_y.sort_values(by=\"date\", inplace=True)\n",
    "X_train_upsampled_with_y.drop(columns=[\"release_date\", \"date\"], inplace=True)\n",
    "\n",
    "# print(X_train_upsampled_with_y.head())\n",
    "# prepro:\n",
    "y_train_upsampled_ordered = X_train_upsampled_with_y[\"hit\"]\n",
    "X_train_upsampled_ordered = X_train_upsampled_with_y.drop(columns=\"hit\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25a24f9a025a9a43"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_upsampled_ordered = X_train_upsampled_ordered.astype(\"float32\")\n",
    "#X_train_upsampled_ordered = X_train_upsampled_ordered.to_numpy()\n",
    "y_train_upsampled_ordered = y_train_upsampled_ordered.to_frame()\n",
    "y_train_upsampled_ordered = y_train_upsampled_ordered.astype(\"float32\")\n",
    "#y_train_upsampled_ordered = y_train_upsampled_ordered.to_numpy().reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e67d87c69f47f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = X_train_upsampled_ordered\n",
    "y_train = y_train_upsampled_ordered"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "648bf59b626619ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#seperate testset\n",
    "X_test['date'] = pd.to_datetime(X_test['release_date'])\n",
    "X_test.sort_values(by=\"date\", inplace=True)\n",
    "go_on = True\n",
    "\n",
    "test_dict = {}\n",
    "\n",
    "X_test_df = pd.concat((X_test.copy(), y_test.copy()), axis=0)\n",
    "while go_on:\n",
    "    split_day = X_test_df[\"date\"].iloc[-1]  - pd.DateOffset(years=1)\n",
    "    value_add_df = X_test_df[(X_test_df[\"date\"]  < split_day)].copy()\n",
    "    if value_add_df.empty:\n",
    "        go_on = False\n",
    "        break\n",
    "    key_add = X_test_df['date'].iloc[-1].dt.strftime('%Y-%m-%d') + \"-\" + split_day.dt.strftime('%Y-%m-%d')\n",
    "    test_dict[key_add] = value_add_df\n",
    "    X_test_df = X_test_df[(X_test_df[\"date\"]  >= split_day)].copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db45b8f173cc9575"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test.drop(columns=[\"release_date\", \"date\"], inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47232f79208eafe1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.input_shape = input_shape\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape[1], 128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.4),\n",
    "            nn.Linear(64, 1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.layers(x)\n",
    "        return torch.sigmoid(logits)\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model {path} is loaded from epoch {checkpoint['epoch']} , loss {checkpoint['loss']}\")\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c613792b3a4940"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#try to drop yoc information for test data \n",
    "#X_test[\"years_on_charts\"] = 0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0b308e713f528b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# convert to Pytorch tensor\n",
    "X_train = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "print(\"######CONVERSION TO TENSOR######\")\n",
    "\n",
    "# Move the data to the GPU if available\n",
    "X_train = X_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_test = y_test.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cf1b3824eb0dfa7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define model\n",
    "print(X_train.size())\n",
    "model = MLPClassifier(X_train.size()).to(device)\n",
    "\n",
    "# Define loss function and optimizer (same as TensorFlow example)\n",
    "loss_fn = nn.BCELoss()  # alternative #BCELoss(weights=weights)#nn.MSELoss()\n",
    "loss_fn_mae = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters())#, weight_decay=0.001) # l2 reg\n",
    "#l1_penalty = torch.nn.L1Loss(size_average=False)\n",
    "\n",
    "# Create DataLoader with oversampled data\n",
    "dataset_train = TensorDataset(X_train, y_train)\n",
    "trainloader = DataLoader(dataset_train, batch_size=256, shuffle=True)#, num_workers=2)#, num_workers=2, pin_memory=True) #last two are new look at later\n",
    "dataset_test = TensorDataset(X_test, y_test)\n",
    "val_loader = DataLoader(dataset_test, batch_size=256, shuffle=False)#, num_workers=2)\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "val_prec = []\n",
    "epochs = 10\n",
    "best_val_loss = 1e8\n",
    "best_val_acc = 0\n",
    "best_precision = 0\n",
    "best_prec_acc = 0.0\n",
    "version = \"v3_try_reg\"\n",
    "\n",
    "lambda1 = 0.001  # L1 penalty strength\n",
    "nweights = 0\n",
    "for name,weights in model.named_parameters():\n",
    "    if 'bias' not in name:\n",
    "        nweights = nweights + weights.numel()\n",
    "print(f'Total number of weights in the model = {nweights}')\n",
    "\n",
    "for epoch in range(epochs):  # Adjust epochs as needed\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "\n",
    "    # Initialize counts for each class\n",
    "\n",
    "    # Training phase\n",
    "    model.train()  # Set model to training mode\n",
    "    for X_batch, y_batch in trainloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch)\n",
    "        # print(\"y_batch: \", y_batch)\n",
    "        # print(\"y_pred: \", y_pred)\n",
    "        #print(y_batch.shape)\n",
    "        y_batch = y_batch.reshape(-1, 1)\n",
    "        #print(y_batch.shape)\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        #l1_norm = 0\n",
    "        #for param in model.parameters():\n",
    "        #    l1_norm += l1_penalty(param)\n",
    "        #l2_norm = sum(torch.square(param) for param in model.parameters())\n",
    "        #l1_norm = sum(param.abs().sum() for param in model.parameters())\n",
    "        #l2_norm = sum(param.pow(2).sum() for param in model.parameters())        \n",
    "        #l1_penalty_var = lambda1 * l1_norm #+ lambda2 * l2_norm\n",
    "        #total_loss = loss + l1_penalty_var\n",
    "        L1_term = torch.tensor(0., requires_grad=True)\n",
    "        for name, weights in model.named_parameters():\n",
    "            if 'bias' not in name:\n",
    "                weights_sum = torch.sum(torch.abs(weights))\n",
    "                L1_term = L1_term + weights_sum\n",
    "        L1_term = L1_term / nweights\n",
    "\n",
    "        # l2_weight = 0.001\n",
    "        # l2_parameters = []\n",
    "        # for parameter in model.parameters():\n",
    "        #     l2_parameters.append(parameter.view(-1))\n",
    "        # l2 = l2_weight * torch.square(torch.cat(l2_parameters)).sum()\n",
    "\n",
    "        # Regularize loss using L1 regularization\n",
    "        total_loss = loss #+ L1_term * lambda1 #+ l2 # -  ?\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += total_loss.item()\n",
    "    # Calculate average epoch training loss\n",
    "    avg_epoch_train_loss = epoch_train_loss / len(trainloader)\n",
    "    train_losses.append(avg_epoch_train_loss)\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        correct, total = 0.0, 0.0\n",
    "        tp, fp =  0.0, 0.0\n",
    "        loss_step = []\n",
    "        for data in val_loader:\n",
    "            inp_data, labels = data\n",
    "            inp_data = inp_data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inp_data)\n",
    "            labels = labels.reshape(-1, 1)\n",
    "            val_loss = loss_fn(outputs, labels)\n",
    "            predicted = outputs.round()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum()\n",
    "            loss_step.append(val_loss.item())\n",
    "            #print(labels.shape)\n",
    "            #print(predicted.shape)\n",
    "            tp  += ((labels == 1) & (1 == predicted)).sum().item()\n",
    "            fp += ((labels == 0) & (1 == predicted)).sum().item()\n",
    "        # dont forget to take the means here\n",
    "        epoch_val_acc = (correct / total).cpu().numpy()\n",
    "        epoch_val_loss = torch.tensor(loss_step).mean().numpy()\n",
    "        #print('TP:', tp, 'FP:', fp)\n",
    "        epoch_val_prec = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_val_loss,\n",
    "            }, f'best_torch_{version}_model_min_val_loss.pth')\n",
    "        if epoch_val_acc > best_val_acc:\n",
    "            best_val_acc = epoch_val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_val_loss,\n",
    "            }, f'best_torch_{version}_model_max_val_acc.pth')\n",
    "        if epoch_val_prec > best_precision or (epoch_val_acc > best_prec_acc and best_precision == epoch_val_prec):\n",
    "            best_precision = epoch_val_prec\n",
    "            best_prec_acc = epoch_val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_val_loss,\n",
    "                'precision': best_precision,\n",
    "            }, f\"best_torch_{version}_model_max_val_prec.pth\")\n",
    "\n",
    "        val_prec.append(epoch_val_prec)\n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_accs.append(epoch_val_acc)\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {avg_epoch_train_loss:.4f}, Validation Loss: {epoch_val_loss:.4f}, Validation Accuracy: {epoch_val_acc:.4f}, Validation Precision: {epoch_val_prec:.4f}\")\n",
    "\n",
    "print(\"######TRAINING DONE######\")\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "    checkpoint = torch.load(path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Model {path} is loaded from epoch {checkpoint['epoch']} , loss {checkpoint['loss']}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"######LOAD MODEL######\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLPClassifier(X_train.size())\n",
    "model = load_model(model, f\"best_torch_{version}_model_max_val_prec.pth\")\n",
    "model = model.to(device)\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a3e4a313da42a70"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the training loss\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss vs. Epoch')\n",
    "plt.legend()\n",
    "plt.savefig(f\"losses_pytorch_{version}.png\")\n",
    "print(\"######LOSS PLOT DONE######\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "output = model(X_test)\n",
    "# print(\"output\", output)\n",
    "\n",
    "opt_thres = -1\n",
    "opt_prec = 0\n",
    "liste_thresh = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "true_labels = y_test.int().tolist()\n",
    "# print(output.tolist())\n",
    "for i in liste_thresh:\n",
    "    flattened_list = [item for sublist in output.tolist() for item in sublist]\n",
    "    predictions = list(map(lambda x: int(x >= i), flattened_list))\n",
    "\n",
    "    precision = metrics.precision_score(true_labels, predictions)\n",
    "\n",
    "    # Recall\n",
    "    recall = metrics.recall_score(true_labels, predictions)\n",
    "    # F1-Score\n",
    "    f1 = metrics.f1_score(true_labels, predictions)\n",
    "    # ROC Curve and AUC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(true_labels, predictions)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    # print(\"Precision:\", precision)\n",
    "    # print(\"Recall:\", recall)\n",
    "    # print(\"F1-Score:\", f1)\n",
    "    # print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "    if precision > opt_prec:\n",
    "        opt_thres = i\n",
    "        opt_prec = precision\n",
    "print(f\"optimal threshold {opt_thres}, with precision {opt_prec}\")\n",
    "\n",
    "predictions = output.round().int().tolist()  # Converting tensor to list of integers\n",
    "true_labels = y_test.int().tolist()  # Converting tensor to list of integers\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(true_labels, predictions)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.savefig(f\"Confusion_Matrix_pytorch_{version}.png\")\n",
    "print(\"######CONFUSION MATRIX PLOT DONE######\")\n",
    "\n",
    "# Extract TN, FP, TP values\n",
    "TN = confusion_matrix[0, 0]  # True Negatives\n",
    "FP = confusion_matrix[0, 1]  # False Positives\n",
    "FN = confusion_matrix[1, 0]  # False Negatives\n",
    "TP = confusion_matrix[1, 1]  # True Positives\n",
    "\n",
    "# Print the results\n",
    "print(\"True Negatives (TN):\", TN)\n",
    "print(\"False Positives (FP):\", FP)\n",
    "print(\"False Negatives (FN):\", FN)\n",
    "print(\"True Positives (TP):\", TP)\n",
    "\n",
    "# Precision \n",
    "precision = metrics.precision_score(true_labels, predictions)\n",
    "# Recall \n",
    "recall = metrics.recall_score(true_labels, predictions)\n",
    "# F1-Score \n",
    "f1 = metrics.f1_score(true_labels, predictions)\n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = metrics.roc_curve(true_labels, predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# print(output.device)\n",
    "output_cpu = output.cpu().detach().numpy()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.tolist(), output_cpu.tolist())\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f\"ROC_AUC_pytorch_{version}.png\")\n",
    "print(\"######ROC-AUC PLOT DONE######\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_test.tolist(), predictions)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "y_test_cpu = y_test.cpu()\n",
    "y_test_list = y_test_cpu.tolist()\n",
    "\n",
    "# Convert predictions to list\n",
    "predictions_list = list(np.hstack(predictions))\n",
    "\n",
    "y_test_series = pd.Series(list(np.hstack(y_test_list)))\n",
    "count_occ = y_test_series.value_counts(normalize=True)\n",
    "\n",
    "# Calculate the weighted accuracy\n",
    "weighted_acc = (np.sum((y_test_series == 1) == predictions_list) * count_occ[0] + np.sum(\n",
    "    (y_test_series == 0) == predictions_list) * count_occ[1]) / len(y_test_list)\n",
    "\n",
    "print(\"Weighted Accuracy:\", weighted_acc)\n",
    "\n",
    "macro_f1 = metrics.f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "856d0380ec2d27df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for test_x in test_dict.values():\n",
    "    test_y = test_x[\"hit\"]\n",
    "    test_x = test_x.drop(columns=[\"release_date\", \"date\", \"hit\"], inplace=True)\n",
    "\n",
    "    output = model(test_x)\n",
    "\n",
    "    true_labels = test_y.int().tolist()\n",
    "    predictions = output.round().int().tolist()  # Converting tensor to list of integers\n",
    "\n",
    "    confusion_matrix = metrics.confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=[False, True])\n",
    "    # \n",
    "    # cm_display.plot()\n",
    "    # plt.savefig(f\"Confusion_Matrix_pytorch_{version}.png\")\n",
    "    # print(\"######CONFUSION MATRIX PLOT DONE######\")\n",
    "\n",
    "    # Extract TN, FP, TP values\n",
    "    TN = confusion_matrix[0, 0]  # True Negatives\n",
    "    FP = confusion_matrix[0, 1]  # False Positives\n",
    "    FN = confusion_matrix[1, 0]  # False Negatives\n",
    "    TP = confusion_matrix[1, 1]  # True Positives\n",
    "\n",
    "    # # Print the results\n",
    "    # print(\"True Negatives (TN):\", TN)\n",
    "    # print(\"False Positives (FP):\", FP)\n",
    "    # print(\"False Negatives (FN):\", FN)\n",
    "    # print(\"True Positives (TP):\", TP)\n",
    "\n",
    "# Precision \n",
    "precision = metrics.precision_score(true_labels, predictions)\n",
    "# Recall \n",
    "recall = metrics.recall_score(true_labels, predictions)\n",
    "# F1-Score \n",
    "f1 = metrics.f1_score(true_labels, predictions)\n",
    "# ROC Curve and AUC \n",
    "fpr, tpr, thresholds = metrics.roc_curve(true_labels, predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"ROC AUC:\", roc_auc)\n",
    "\n",
    "# print(output.device)\n",
    "output_cpu = output.cpu().detach().numpy()\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test.tolist(), output_cpu.tolist())\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(f\"ROC_AUC_pytorch_{version}.png\")\n",
    "print(\"######ROC-AUC PLOT DONE######\")\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(y_test.tolist(), predictions)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "y_test_cpu = y_test.cpu()\n",
    "y_test_list = y_test_cpu.tolist()\n",
    "\n",
    "# Convert predictions to list\n",
    "predictions_list = list(np.hstack(predictions))\n",
    "\n",
    "y_test_series = pd.Series(list(np.hstack(y_test_list)))\n",
    "count_occ = y_test_series.value_counts(normalize=True)\n",
    "\n",
    "# Calculate the weighted accuracy\n",
    "weighted_acc = (np.sum((y_test_series == 1) == predictions_list) * count_occ[0] + np.sum(\n",
    "    (y_test_series == 0) == predictions_list) * count_occ[1]) / len(y_test_list)\n",
    "\n",
    "print(\"Weighted Accuracy:\", weighted_acc)\n",
    "\n",
    "macro_f1 = metrics.f1_score(true_labels, predictions, average='macro')\n",
    "\n",
    "print(\"Macro F1 Score:\", macro_f1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c0f172ad55f97b1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
