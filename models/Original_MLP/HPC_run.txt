ssh ladan102@hpc.rz.uni-duesseldorf.de

qsub -l select=1:ncpus=1:mem=20gb:ngpus=1:accelerator_model=rtx6000 -l walltime=47:59:00 -A "HSS_BA"

qsub -I -l select=1:ncpus=1:mem=20gb:ngpus=1:accelerator_model=rtx6000 -l walltime=47:59:00 -A "HSS_BA"


cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python First_MLP.py 2> error_first_mlp.err 1> output_first_mlp.out
python model_all.py 2> error_all.err 1> output_all.out

PIP_CONFIG_FILE=/software/python/pip.conf pip install --user $PACKAGE_NAME

module avail

pip freeze

pip uninstall -r <(pip freeze)
pip install --upgrade -r <(pip freeze)

module load Miniconda/3

conda create -c http://conda.repo.test.hhu.de/bioconda -c http://conda.repo.test.hhu.de/main -c http://conda.repo.test.hhu.de/conda-forge --override-channels --name my_environment

environment location: /home/ladan102/.conda/envs/BA

conda activate BA

conda install -c http://conda.repo.test.hhu.de/bioconda -c http://conda.repo.test.hhu.de/main -c http://conda.repo.test.hhu.de/conda-forge --override-channels $PACKAGE_NAME

check python version and compat

run file:

If activating your conda environment works for you in interactive mode but not in batch mode, then you might need to source your files .bashrc and .bash_profile.
This is because in interactive mode you'll get a login shell but in batch mode not. In your jobscript such a solution could look as follows:

#!/bin/bash
#PBS -l select=1:ncpus=X:mem=XGB
#PBS -l walltime=X:00:00
#PBS -A 'XXX'
# source bash
source $HOME/.bashrc
source $HOME/.bash_profile

qsub -l select=1:ncpus=4:mem=20gb:ngpus=4:accelerator_model=rtx6000 -l walltime=47:59:00 -A "HSS_BA"

qsub -l select=1:ncpus=2:mem=20gb:ngpus=1:accelerator_model=rtx6000 -l walltime=47:59:00 -A "HSS_BA"

qsub -I -l select=1:ncpus=4:mem=20gb -l walltime=95:59:00 -A "HSS_BA"

qsub -I -l select=1:ncpus=2:mem=10gb -l walltime=47:59:00 -A "HSS_BA"

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python MLP_pytorch_v1.py 2> error_pytorch_v1_d.err 1> output_pytorch_v1_d_04.txt

cd /gpfs/project/ladan102/Ba_try/random_tries
module load Miniconda/3
conda activate BA

python MLP_best_comb.py 2> error_bes.err 1> output_best.txt
python RandomForest_sklearn.py 2> error_for.err 1> output_for.txt
python try.py 2> error_try.err 1> output_try_200.txt

python MLP_pytorch_v3.py 2> error_pytorch_v3.err 1> output_pytorch_v3.txt

python MLP_pytorch_v3_comb.py 2> error_pytorch_comb.err
python MLP_comb.py 2> error_comb_sklearn.err

python MLP_reg_torch.py 2> error_reg.err 1> output_reg.txt

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python First_MLP.py 2> error_first_mlp.err 1> output_first_mlp.out

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python MLP_sklearn.py 2> error_sklearn_mlp.err 1> output_sklearn.out

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python MLP_collab.py 2> error_collab_mlp.err 1> output_collab.out

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python MLP_collab_try.py 2> error_collab_mlp.err 1> output_collab_try.out

cd /gpfs/project/ladan102/Ba_try
module load Miniconda/3
conda activate BA
python MLP_collab_good_structure.py 2> error_collab_mlp_structure.err 1> output_collab_structure.out

eval on hpc:
python sup_comb/eval_sup.py 1> sup_comb/eval_sup.txt
python end_comb/eval_comb.py 1> end_comb/eval_end_comb.txt


.condarc

To make your life super easy and just ignore all of the above (and thus also keep your existing .yaml files) you can also just create a .condarc file in your home directory with the following contents (this handles the redirection of the channels to the custom hhu ones for you):

channel_alias: http://conda.repo.test.hhu.de/

default_channels:
  - http://conda.repo.test.hhu.de/main
  - http://conda.repo.test.hhu.de/bioconda
  - http://conda.repo.test.hhu.de/conda-forge


  Install individual Python kernel

  Jupyter allows you to work with your own environment. You can use e.g. conda for this task. Start by creating a new conda environment:
  module load Miniconda/3.1
  conda create -p /gpfs/project/$USER/py310 python=3.10
  conda activate /gpfs/project/$USER/py310

  Hint: this only works if you have defined a .condarc with channels pointing to our repo server (see also Conda)

  Install the programs that you need with conda install , at least  ipykernel must be installed:
  conda install ipykernel

  Create a new file "kernel.sh" in the main directory of your environment and make it executable
  cd /gpfs/project/$USER/py310
  vi kernel.sh

  kernel.sh
  ----------------------------------------------------
  #!/bin/bash
  export PYTHONPATH=/gpfs/project/$USER/py310/lib/python3.10/site-packages
  export PATH=/gpfs/project/$USER/py310/bin:$PATH
  exec python -m ipykernel $@
  ----------------------------------------------------

  chmod a+x kernel.sh

  Create a new directory for your kernel in your /home/.local/share folder
  mkdir -p /home/$USER/.local/share/jupyter/kernels/py310
  cd /home/$USER/.local/share/jupyter/kernels/py310

  Create a new file "kernel.json" with contents (!!replace $USER with your explicit username here!!)
  {
  "argv": [
    "/gpfs/project/$USER/py310/kernel.sh",
    "-f",
    "{connection_file}"
   ],
   "display_name": "Python 3.10 (conda)",
   "language": "python",
   "metadata": {
    "debugger": true
   }
  }