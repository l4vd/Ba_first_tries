output sup1 and sup native: (only x)
Iteration 200, loss = 0.05668539
Accuracy: 0.9906567086851337
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 223786
False Positives (FP): 1845
False Negatives (FN): 283
True Positives (TP): 1843
Precision: 0.4997288503253796
Recall: 0.8668861712135466
F1-Score: 0.6339869281045752
ROC AUC: 0.961369492125216
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      1.00    225631
         1.0       0.50      0.87      0.63      2126

    accuracy                           0.99    227757
   macro avg       0.75      0.93      0.81    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9814966287520068
Macro F1 Score: 0.8146274422599816

evtl leakage durch present Verschiebung in chart data

superstarv1: (only x)
Iteration 200, loss = 0.05613991
Accuracy: 0.9798820672910163
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221317
False Positives (FP): 4314
False Negatives (FN): 268
True Positives (TP): 1858
Precision: 0.30103694102397927
Recall: 0.8739416745061148
F1-Score: 0.44781875150638706
ROC AUC: 0.9588978765448475
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.30      0.87      0.45      2126

    accuracy                           0.98    227757
   macro avg       0.65      0.93      0.72    227757
weighted avg       0.99      0.98      0.98    227757

Weighted Accuracy: 0.9709231393541301
Macro F1 Score: 0.7187865715601414

=> worse than MLP_song

superstar: (only x)
Iteration 200, loss = 0.05762122
Accuracy: 0.9808480090622901
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221529
False Positives (FP): 4102
False Negatives (FN): 260
True Positives (TP): 1866
Precision: 0.31266756032171583
Recall: 0.8777046095954845
F1-Score: 0.4610822831727205
ROC AUC: 0.9651354062125086
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.31      0.88      0.46      2126

    accuracy                           0.98    227757
   macro avg       0.66      0.93      0.73    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9718710479391068
Macro F1 Score: 0.7256665271301446

=> also worse than song

previous version probably with leakage

both x:
Iteration 194, loss = 0.05223463
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9798381608468675
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221302
False Positives (FP): 4329
False Negatives (FN): 263
True Positives (TP): 1863
Precision: 0.3008720930232558
Recall: 0.8762935089369709
F1-Score: 0.4479442173599423
ROC AUC: 0.9590964312384552
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.30      0.88      0.45      2126

    accuracy                           0.98    227757
   macro avg       0.65      0.93      0.72    227757
weighted avg       0.99      0.98      0.98    227757

Weighted Accuracy: 0.9708800526002676
Macro F1 Score: 0.7188378945993443

superstar_v1_x:
Iteration 194, loss = 0.05493569
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9841497736622804
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 222288
False Positives (FP): 3343
False Negatives (FN): 267
True Positives (TP): 1859
Precision: 0.357362552864283
Recall: 0.874412041392286
F1-Score: 0.5073689956331878
ROC AUC: 0.962405314093679
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99    225631
         1.0       0.36      0.87      0.51      2126

    accuracy                           0.98    227757
   macro avg       0.68      0.93      0.75    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9751111718295726
Macro F1 Score: 0.7496571520271227

superstar_x:
Iteration 200, loss = 0.05847380
Accuracy: 0.9836185056880798
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 222171
False Positives (FP): 3460
False Negatives (FN): 271
True Positives (TP): 1855
Precision: 0.34901222953904043
Recall: 0.8725305738476011
F1-Score: 0.4985888993414863
ROC AUC: 0.9641375586500379
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.35      0.87      0.50      2126

    accuracy                           0.98    227757
   macro avg       0.67      0.93      0.75    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9745898221078355
Macro F1 Score: 0.7451310655793117


however for 10 epochs:
Iteration 1, loss = 0.16187033
Iteration 2, loss = 0.09497665
Iteration 3, loss = 0.09120893
Iteration 4, loss = 0.08909955
Iteration 5, loss = 0.08787184
Iteration 6, loss = 0.08668665
Iteration 7, loss = 0.08571741
Iteration 8, loss = 0.08470067
Iteration 9, loss = 0.08394796
Iteration 10, loss = 0.08313755
Accuracy: 0.9955259333412365
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224902
False Positives (FP): 729
False Negatives (FN): 290
True Positives (TP): 1836
Precision: 0.7157894736842105
Recall: 0.863593603010348
F1-Score: 0.7827755276060542
ROC AUC: 0.971010880271872
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00    225631
         1.0       0.72      0.86      0.78      2126

    accuracy                           1.00    227757
   macro avg       0.86      0.93      0.89    227757
weighted avg       1.00      1.00      1.00    227757

Weighted Accuracy: 0.9862749497553669
Macro F1 Score: 0.8902576085092644

=> yields significant improvements in comparison to song:

song 10 it:
######PREPROCESSING DONE######
Iteration 1, loss = 0.16412455
Iteration 2, loss = 0.10142206
Iteration 3, loss = 0.09827546
Iteration 4, loss = 0.09674345
Iteration 5, loss = 0.09541484
Iteration 6, loss = 0.09449503
Iteration 7, loss = 0.09354152
Iteration 8, loss = 0.09265587
Iteration 9, loss = 0.09193678
Iteration 10, loss = 0.09106864
Accuracy: 0.9932559701787431
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224375
False Positives (FP): 1256
False Negatives (FN): 280
True Positives (TP): 1846
Precision: 0.5950999355254675
Recall: 0.8682972718720602
F1-Score: 0.7061973986228003
ROC AUC: 0.9727215880699792
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      1.00    225631
         1.0       0.60      0.87      0.71      2126

    accuracy                           0.99    227757
   macro avg       0.80      0.93      0.85    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9840473645806715
Macro F1 Score: 0.8513931166372775

=> one could assume we have faster overfitting upon which we cannot judge due to the lack of val calculations

try with reduced test ds because superstar is more relevant in that case.
test ds till index 105500:
Iteration 194, loss = 0.05223463
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9784739336492891
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 102339
False Positives (FP): 2148
False Negatives (FN): 123
True Positives (TP): 890
Precision: 0.29295589203423306
Recall: 0.87857847976308
F1-Score: 0.43939767958528764
ROC AUC: 0.9646122557829216
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    104487
         1.0       0.29      0.88      0.44      1013

    accuracy                           0.98    105500
   macro avg       0.65      0.93      0.71    105500
weighted avg       0.99      0.98      0.98    105500

Weighted Accuracy: 0.9692854200040432
Macro F1 Score: 0.7142119807114209

=> even worse than before due to the lack of date information to evaluate the relevance of the superstar var

try include date:
teration 175, loss = 0.05313391
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9816303317535545
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 102675
False Positives (FP): 1812
False Negatives (FN): 126
True Positives (TP): 887
Precision: 0.32864023712486107
Recall: 0.8756169792694966
F1-Score: 0.47790948275862066
ROC AUC: 0.9622649911690484
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    104487
         1.0       0.33      0.88      0.48      1013

    accuracy                           0.98    105500
   macro avg       0.66      0.93      0.73    105500
weighted avg       0.99      0.98      0.99    105500

Weighted Accuracy: 0.9723812032973204
Macro F1 Score: 0.7342800858276142

-> better but still worse than song and single ones

with date init with nan:
Iteration 161, loss = 0.05022737
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9899585962231676
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 223620
False Positives (FP): 2011
False Negatives (FN): 276
True Positives (TP): 1850
Precision: 0.47915047915047915
Recall: 0.8701787394167451
F1-Score: 0.618005678971104
ROC AUC: 0.9629493429053964
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99    225631
         1.0       0.48      0.87      0.62      2126

    accuracy                           0.99    227757
   macro avg       0.74      0.93      0.81    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9808115493655918
Macro F1 Score: 0.8064590545738559

-> yields better results than just song

(=> superstar is better)

superstar v1 and native without date init nan:
Iteration 161, loss = 0.05022737
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9899585962231676
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 223620
False Positives (FP): 2011
False Negatives (FN): 276
True Positives (TP): 1850
Precision: 0.47915047915047915
Recall: 0.8701787394167451
F1-Score: 0.618005678971104
ROC AUC: 0.9629493429053964
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99    225631
         1.0       0.48      0.87      0.62      2126

    accuracy                           0.99    227757
   macro avg       0.74      0.93      0.81    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9808115493655918
Macro F1 Score: 0.8064590545738559

-> superstar better than song

version superstar_v1_x, superstar_x, hits_in_past_x:
Iteration 133, loss = 0.05485592
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.995543495918896
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224904
False Positives (FP): 727
False Negatives (FN): 288
True Positives (TP): 1838
Precision: 0.7165692007797271
Recall: 0.8645343367826905
F1-Score: 0.7836282242592199
ROC AUC: 0.9579358540903579
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00    225631
         1.0       0.72      0.86      0.78      2126

    accuracy                           1.00    227757
   macro avg       0.86      0.93      0.89    227757
weighted avg       1.00      1.00      1.00    227757

Weighted Accuracy: 0.9862921844569118
Macro F1 Score: 0.8906883931667353

-> even better :)

try superstar for all variations:
Iteration 200, loss = 0.04845614
Accuracy: 0.9803562568878235
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221428
False Positives (FP): 4203
False Negatives (FN): 271
True Positives (TP): 1855
Precision: 0.30620666886761305
Recall: 0.8725305738476011
F1-Score: 0.4533235581622678
ROC AUC: 0.9604226523452345
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.31      0.87      0.45      2126

    accuracy                           0.98    227757
   macro avg       0.65      0.93      0.72    227757
weighted avg       0.99      0.98      0.98    227757

Weighted Accuracy: 0.9713884762958459
Macro F1 Score: 0.7216609966609967

-> worse

now trying with pytorch network 10 iter:
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224693
False Positives (FP): 938
False Negatives (FN): 293
True Positives (TP): 1833
Precision: 0.6614940454709491
Recall: 0.8621825023518345
F1-Score: 0.7486216050643252
ROC AUC: 0.9290126360919971
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00    225631
         1.0       0.66      0.86      0.75      2126

    accuracy                           0.99    227757
   macro avg       0.83      0.93      0.87    227757
weighted avg       1.00      0.99      0.99    227757

Weighted Accuracy: 0.9853615105734802
Macro F1 Score: 0.8729448975618663

=> compareable results -> assume the networks are similar.
Now execute for 200 epochs and check where best fit exists.

turns out for 200 epochs the song net is better (maybe due to the decreasing relevance of superstar over time)






on Small Dataset (6 years)

sup supv1 amount hits:
Iteration 200, loss = 0.03551045
Accuracy: 0.9865105496573041
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 58209
False Positives (FP): 737
False Negatives (FN): 66
True Positives (TP): 516
Precision: 0.4118116520351157
Recall: 0.8865979381443299
F1-Score: 0.5623978201634877
ROC AUC: 0.9776014199261879
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99     58946
         1.0       0.41      0.89      0.56       582

    accuracy                           0.99     59528
   macro avg       0.71      0.94      0.78     59528
weighted avg       0.99      0.99      0.99     59528

Weighted Accuracy: 0.9769974082817984
Macro F1 Score: 0.7777737558858233


small:::6years

sup nat:
Iteration 200, loss = 0.05283919
Accuracy: 0.9794101382488479
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52650
False Positives (FP): 1067
False Negatives (FN): 50
True Positives (TP): 483
Precision: 0.3116129032258064
Recall: 0.9061913696060038
F1-Score: 0.4637542006721075
ROC AUC: 0.9788533025258739
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.31      0.91      0.46       533

    accuracy                           0.98     54250
   macro avg       0.66      0.94      0.73     54250
weighted avg       0.99      0.98      0.98     54250

Weighted Accuracy: 0.9699898394954235
Macro F1 Score: 0.7266288787173274

sup v1:
Iteration 200, loss = 0.05130686
Accuracy: 0.9868571428571429
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 53056
False Positives (FP): 661
False Negatives (FN): 52
True Positives (TP): 481
Precision: 0.4211908931698774
Recall: 0.9024390243902439
F1-Score: 0.5743283582089552
ROC AUC: 0.9761858242493204
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99     53717
         1.0       0.42      0.90      0.57       533

    accuracy                           0.99     54250
   macro avg       0.71      0.95      0.78     54250
weighted avg       0.99      0.99      0.99     54250

Weighted Accuracy: 0.9772905121790652
Macro F1 Score: 0.7838269453108899

sup v2:
Iteration 200, loss = 0.05059327
Accuracy: 0.9819354838709677
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52787
False Positives (FP): 930
False Negatives (FN): 50
True Positives (TP): 483
Precision: 0.34182590233545646
Recall: 0.9061913696060038
F1-Score: 0.4964028776978417
ROC AUC: 0.9777914873937525
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.34      0.91      0.50       533

    accuracy                           0.98     54250
   macro avg       0.67      0.94      0.74     54250
weighted avg       0.99      0.98      0.99     54250

Weighted Accuracy: 0.9724655626579456
Macro F1 Score: 0.7436028315699824

sup v3:
Iteration 200, loss = 0.05252628
Accuracy: 0.9859539170506912
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 53004
False Positives (FP): 713
False Negatives (FN): 49
True Positives (TP): 484
Precision: 0.404344193817878
Recall: 0.9080675422138836
F1-Score: 0.5595375722543352
ROC AUC: 0.9760265222915689
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99     53717
         1.0       0.40      0.91      0.56       533

    accuracy                           0.99     54250
   macro avg       0.70      0.95      0.78     54250
weighted avg       0.99      0.99      0.99     54250

Weighted Accuracy: 0.9764050345515937
Macro F1 Score: 0.7762003680321972

sup v4:
Iteration 200, loss = 0.05586213
Accuracy: 0.9822857142857143
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52810
False Positives (FP): 907
False Negatives (FN): 54
True Positives (TP): 479
Precision: 0.34559884559884557
Recall: 0.8986866791744841
F1-Score: 0.4992183428869202
ROC AUC: 0.9766204555938196
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.35      0.90      0.50       533

    accuracy                           0.98     54250
   macro avg       0.67      0.94      0.75     54250
weighted avg       0.99      0.98      0.99     54250

Weighted Accuracy: 0.9728089111257405
Macro F1 Score: 0.7451008632084087

Weighted Accuracy: 0.9773989380110004
Macro F1 Score: 0.7843788469519737

sup v5:
Iteration 200, loss = 0.05394328
Accuracy: 0.9840552995391705
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52902
False Positives (FP): 815
False Negatives (FN): 50
True Positives (TP): 483
Precision: 0.37211093990755006
Recall: 0.9061913696060038
F1-Score: 0.5275805570726378
ROC AUC: 0.981537825168878
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.37      0.91      0.53       533

    accuracy                           0.98     54250
   macro avg       0.69      0.95      0.76     54250
weighted avg       0.99      0.98      0.99     54250

Weighted Accuracy: 0.9745437244367049
Macro F1 Score: 0.7597356797306678

hi i past:
Iteration 200, loss = 0.05214930
Accuracy: 0.9858433179723503
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52999
False Positives (FP): 718
False Negatives (FN): 50
True Positives (TP): 483
Precision: 0.4021648626144879
Recall: 0.9061913696060038
F1-Score: 0.5570934256055363
ROC AUC: 0.979919239041686
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99     53717
         1.0       0.40      0.91      0.56       533

    accuracy                           0.99     54250
   macro avg       0.70      0.95      0.77     54250
weighted avg       0.99      0.99      0.99     54250

Weighted Accuracy: 0.9762966087196585
Macro F1 Score: 0.7749500621836571

success r:
Iteration 200, loss = 0.05466163
Accuracy: 0.9809769585253456
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52732
False Positives (FP): 985
False Negatives (FN): 47
True Positives (TP): 486
Precision: 0.33038749150237934
Recall: 0.9118198874296435
F1-Score: 0.48502994011976047
ROC AUC: 0.9800638367406758
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.33      0.91      0.49       533

    accuracy                           0.98     54250
   macro avg       0.66      0.95      0.74     54250
weighted avg       0.99      0.98      0.99     54250

Weighted Accuracy: 0.9715258721145065
Macro F1 Score: 0.7376697176560341

comb:

sup nat v1:
Iteration 200, loss = 0.03709904
Accuracy: 0.9824884792626728
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 52816
False Positives (FP): 901
False Negatives (FN): 49
True Positives (TP): 484
Precision: 0.34945848375451266
Recall: 0.9080675422138836
F1-Score: 0.5046923879040668
ROC AUC: 0.9782551779859713
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99     53717
         1.0       0.35      0.91      0.50       533

    accuracy                           0.98     54250
   macro avg       0.67      0.95      0.75     54250
weighted avg       0.99      0.98      0.99     54250

Weighted Accuracy: 0.9730076918176219
Macro F1 Score: 0.7478895314761932

sup nat v1 v2
