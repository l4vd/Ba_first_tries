output sup1 and sup native: (only x)
Iteration 200, loss = 0.05668539
Accuracy: 0.9906567086851337
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 223786
False Positives (FP): 1845
False Negatives (FN): 283
True Positives (TP): 1843
Precision: 0.4997288503253796
Recall: 0.8668861712135466
F1-Score: 0.6339869281045752
ROC AUC: 0.961369492125216
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      1.00    225631
         1.0       0.50      0.87      0.63      2126

    accuracy                           0.99    227757
   macro avg       0.75      0.93      0.81    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9814966287520068
Macro F1 Score: 0.8146274422599816

evtl leakage durch present Verschiebung in chart data

superstarv1: (only x)
Iteration 200, loss = 0.05613991
Accuracy: 0.9798820672910163
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221317
False Positives (FP): 4314
False Negatives (FN): 268
True Positives (TP): 1858
Precision: 0.30103694102397927
Recall: 0.8739416745061148
F1-Score: 0.44781875150638706
ROC AUC: 0.9588978765448475
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.30      0.87      0.45      2126

    accuracy                           0.98    227757
   macro avg       0.65      0.93      0.72    227757
weighted avg       0.99      0.98      0.98    227757

Weighted Accuracy: 0.9709231393541301
Macro F1 Score: 0.7187865715601414

=> worse than MLP_song

superstar: (only x)
Iteration 200, loss = 0.05762122
Accuracy: 0.9808480090622901
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221529
False Positives (FP): 4102
False Negatives (FN): 260
True Positives (TP): 1866
Precision: 0.31266756032171583
Recall: 0.8777046095954845
F1-Score: 0.4610822831727205
ROC AUC: 0.9651354062125086
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.31      0.88      0.46      2126

    accuracy                           0.98    227757
   macro avg       0.66      0.93      0.73    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9718710479391068
Macro F1 Score: 0.7256665271301446

=> also worse than song

previous version probably with leakage

both x:
Iteration 194, loss = 0.05223463
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9798381608468675
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 221302
False Positives (FP): 4329
False Negatives (FN): 263
True Positives (TP): 1863
Precision: 0.3008720930232558
Recall: 0.8762935089369709
F1-Score: 0.4479442173599423
ROC AUC: 0.9590964312384552
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.30      0.88      0.45      2126

    accuracy                           0.98    227757
   macro avg       0.65      0.93      0.72    227757
weighted avg       0.99      0.98      0.98    227757

Weighted Accuracy: 0.9708800526002676
Macro F1 Score: 0.7188378945993443

superstar_v1_x:
Iteration 194, loss = 0.05493569
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9841497736622804
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 222288
False Positives (FP): 3343
False Negatives (FN): 267
True Positives (TP): 1859
Precision: 0.357362552864283
Recall: 0.874412041392286
F1-Score: 0.5073689956331878
ROC AUC: 0.962405314093679
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99    225631
         1.0       0.36      0.87      0.51      2126

    accuracy                           0.98    227757
   macro avg       0.68      0.93      0.75    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9751111718295726
Macro F1 Score: 0.7496571520271227

superstar_x:
Iteration 200, loss = 0.05847380
Accuracy: 0.9836185056880798
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 222171
False Positives (FP): 3460
False Negatives (FN): 271
True Positives (TP): 1855
Precision: 0.34901222953904043
Recall: 0.8725305738476011
F1-Score: 0.4985888993414863
ROC AUC: 0.9641375586500379
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    225631
         1.0       0.35      0.87      0.50      2126

    accuracy                           0.98    227757
   macro avg       0.67      0.93      0.75    227757
weighted avg       0.99      0.98      0.99    227757

Weighted Accuracy: 0.9745898221078355
Macro F1 Score: 0.7451310655793117


however for 10 epochs:
Iteration 1, loss = 0.16187033
Iteration 2, loss = 0.09497665
Iteration 3, loss = 0.09120893
Iteration 4, loss = 0.08909955
Iteration 5, loss = 0.08787184
Iteration 6, loss = 0.08668665
Iteration 7, loss = 0.08571741
Iteration 8, loss = 0.08470067
Iteration 9, loss = 0.08394796
Iteration 10, loss = 0.08313755
Accuracy: 0.9955259333412365
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224902
False Positives (FP): 729
False Negatives (FN): 290
True Positives (TP): 1836
Precision: 0.7157894736842105
Recall: 0.863593603010348
F1-Score: 0.7827755276060542
ROC AUC: 0.971010880271872
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00    225631
         1.0       0.72      0.86      0.78      2126

    accuracy                           1.00    227757
   macro avg       0.86      0.93      0.89    227757
weighted avg       1.00      1.00      1.00    227757

Weighted Accuracy: 0.9862749497553669
Macro F1 Score: 0.8902576085092644

=> yields significant improvements in comparison to song:

song 10 it:
######PREPROCESSING DONE######
Iteration 1, loss = 0.16412455
Iteration 2, loss = 0.10142206
Iteration 3, loss = 0.09827546
Iteration 4, loss = 0.09674345
Iteration 5, loss = 0.09541484
Iteration 6, loss = 0.09449503
Iteration 7, loss = 0.09354152
Iteration 8, loss = 0.09265587
Iteration 9, loss = 0.09193678
Iteration 10, loss = 0.09106864
Accuracy: 0.9932559701787431
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224375
False Positives (FP): 1256
False Negatives (FN): 280
True Positives (TP): 1846
Precision: 0.5950999355254675
Recall: 0.8682972718720602
F1-Score: 0.7061973986228003
ROC AUC: 0.9727215880699792
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      1.00    225631
         1.0       0.60      0.87      0.71      2126

    accuracy                           0.99    227757
   macro avg       0.80      0.93      0.85    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9840473645806715
Macro F1 Score: 0.8513931166372775

=> one could assume we have faster overfitting upon which we cannot judge due to the lack of val calculations

try with reduced test ds because superstar is more relevant in that case.
test ds till index 105500:
Iteration 194, loss = 0.05223463
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9784739336492891
optimal threshold 1.0, with precision 1.0
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 102339
False Positives (FP): 2148
False Negatives (FN): 123
True Positives (TP): 890
Precision: 0.29295589203423306
Recall: 0.87857847976308
F1-Score: 0.43939767958528764
ROC AUC: 0.9646122557829216
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    104487
         1.0       0.29      0.88      0.44      1013

    accuracy                           0.98    105500
   macro avg       0.65      0.93      0.71    105500
weighted avg       0.99      0.98      0.98    105500

Weighted Accuracy: 0.9692854200040432
Macro F1 Score: 0.7142119807114209

=> even worse than before due to the lack of date information to evaluate the relevance of the superstar var

try include date:
teration 175, loss = 0.05313391
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9816303317535545
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 102675
False Positives (FP): 1812
False Negatives (FN): 126
True Positives (TP): 887
Precision: 0.32864023712486107
Recall: 0.8756169792694966
F1-Score: 0.47790948275862066
ROC AUC: 0.9622649911690484
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.98      0.99    104487
         1.0       0.33      0.88      0.48      1013

    accuracy                           0.98    105500
   macro avg       0.66      0.93      0.73    105500
weighted avg       0.99      0.98      0.99    105500

Weighted Accuracy: 0.9723812032973204
Macro F1 Score: 0.7342800858276142

-> better but still worse than song and single ones

with date init with nan:
Iteration 161, loss = 0.05022737
Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.
Accuracy: 0.9899585962231676
######TRAIN VAL LOSS PLOT DONE######
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 223620
False Positives (FP): 2011
False Negatives (FN): 276
True Positives (TP): 1850
Precision: 0.47915047915047915
Recall: 0.8701787394167451
F1-Score: 0.618005678971104
ROC AUC: 0.9629493429053964
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.99      0.99    225631
         1.0       0.48      0.87      0.62      2126

    accuracy                           0.99    227757
   macro avg       0.74      0.93      0.81    227757
weighted avg       0.99      0.99      0.99    227757

Weighted Accuracy: 0.9808115493655918
Macro F1 Score: 0.8064590545738559

-> yields better results than just song

=> superstar is better

now trying with pytorch network 10 iter:
######CONFUSION MATRIX PLOT DONE######
True Negatives (TN): 224693
False Positives (FP): 938
False Negatives (FN): 293
True Positives (TP): 1833
Precision: 0.6614940454709491
Recall: 0.8621825023518345
F1-Score: 0.7486216050643252
ROC AUC: 0.9290126360919971
######ROC-AUC PLOT DONE######
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00    225631
         1.0       0.66      0.86      0.75      2126

    accuracy                           0.99    227757
   macro avg       0.83      0.93      0.87    227757
weighted avg       1.00      0.99      0.99    227757

Weighted Accuracy: 0.9853615105734802
Macro F1 Score: 0.8729448975618663

=> compareable results -> assume the networks are similar.
Now execute for 200 epochs and check where best fit exists.

turns out for 200 epochs the song net is better (maybe due to the decreasing relevance of superstar over time)